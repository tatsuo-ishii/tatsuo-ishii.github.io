<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Pgpool-II + Watchdogの構築の例</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"><LINK
REV="MADE"
HREF="mailto:pgsql-docs@postgresql.org"><LINK
REL="HOME"
TITLE="Pgpool-II 4.1devel 文書"
HREF="index.html"><LINK
REL="UP"
TITLE="設定の例"
HREF="example-configs.html"><LINK
REL="PREVIOUS"
TITLE="Watchdogの設定例"
HREF="example-watchdog.html"><LINK
REL="NEXT"
TITLE="AWS設定の例"
HREF="example-aws.html"><LINK
REL="STYLESHEET"
TYPE="text/css"
HREF="stylesheet.css"><META
HTTP-EQUIV="Content-Type"
CONTENT="text/html; charset=utf-8"><META
NAME="creation"
CONTENT="2019-07-25T04:21:25"></HEAD
><BODY
CLASS="SECT1"
><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="4"
ALIGN="center"
VALIGN="bottom"
><A
HREF="index.html"
>Pgpool-II 4.1devel 文書</A
></TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
TITLE="Watchdogの設定例"
HREF="example-watchdog.html"
ACCESSKEY="P"
>前のページ</A
></TD
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
HREF="example-configs.html"
ACCESSKEY="U"
>上に戻る</A
></TD
><TD
WIDTH="60%"
ALIGN="center"
VALIGN="bottom"
>第 8章設定の例</TD
><TD
WIDTH="20%"
ALIGN="right"
VALIGN="top"
><A
TITLE="AWS設定の例"
HREF="example-aws.html"
ACCESSKEY="N"
>次のページ</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="EXAMPLE-CLUSTER"
>8.3. <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> + Watchdogの構築の例</A
></H1
><P
>ここでは、ストリーミングレプリケーション構成の<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>を<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>で管理するシステムの構成例を示します。この例では、3台の<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を使って<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>を管理し、単一障害点やスプリットブレインの起きない堅牢なクラスタを運用することが可能です。
    </P
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-REQUIREMENT"
>8.3.1. 前提条件</A
></H2
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>サーバと<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>サーバが同じサブネットにあることを前提とします。
        </P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-STRUCTURE"
>8.3.2. 全体構成</A
></H2
><P
>今回は、Linuxサーバを3台用意し、それぞれのホスト名は 「server1」、「server2」、「server3」 とします。使用するOSはすべてCentOS 7.4とします。それぞれのサーバに<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>と<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>をインストールします。3台の<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>がストリーミングレプリケーション構成になります。全体構成図は以下の通りです。
        </P
><P
>          <DIV
CLASS="FIGURE"
><A
NAME="AEN5884"
></A
><P
><B
>図 8-1. 全体構成図</B
></P
><DIV
CLASS="MEDIAOBJECT"
><P
><IMG
SRC="cluster_40.gif"></P
></DIV
></DIV
>
        </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>注意: </B
>「アクティブ」「スタンバイ」「Primary」「Standby」といった役割は固定されているものではなく、運用と共に変化することがあります。
          </P
></BLOCKQUOTE
></DIV
><DIV
CLASS="TABLE"
><A
NAME="EXAMPLE-CLUSTER-TABLE-IP"
></A
><P
><B
>表 8-2. ホスト名とIPアドレス</B
></P
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL><COL><COL><THEAD
><TR
><TH
>ホスト名</TH
><TH
>IPアドバイス</TH
><TH
>仮想IP</TH
></TR
></THEAD
><TBODY
><TR
><TD
>server1</TD
><TD
>192.168.137.101</TD
><TD
ROWSPAN="3"
>192.168.137.150</TD
></TR
><TR
><TD
>server2</TD
><TD
>192.168.137.102</TD
></TR
><TR
><TD
>server3</TD
><TD
>192.168.137.103</TD
></TR
></TBODY
></TABLE
></DIV
><DIV
CLASS="TABLE"
><A
NAME="EXAMPLE-CLUSTER-TABLE-POSTGRESQL-CONFIG"
></A
><P
><B
>表 8-3. PostgreSQLのバージョンと設定情報</B
></P
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL><COL><COL><THEAD
><TR
><TH
>項目</TH
><TH
>値</TH
><TH
>説明</TH
></TR
></THEAD
><TBODY
><TR
><TD
>PostgreSQLバージョン</TD
><TD
>11.1</TD
><TD
>-</TD
></TR
><TR
><TD
>ポート番号</TD
><TD
>5432</TD
><TD
>-</TD
></TR
><TR
><TD
>$PGDATA</TD
><TD
>/var/lib/pgsql/11/data</TD
><TD
>-</TD
></TR
><TR
><TD
>アーカイブモード</TD
><TD
>有効</TD
><TD
>/var/lib/pgsql/archivedir</TD
></TR
><TR
><TD
>自動起動</TD
><TD
>自動起動しない</TD
><TD
>-</TD
></TR
></TBODY
></TABLE
></DIV
><DIV
CLASS="TABLE"
><A
NAME="EXAMPLE-CLUSTER-TABLE-PGPOOL-CONFIG"
></A
><P
><B
>表 8-4. Pgpool-IIのバージョンと設定情報</B
></P
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL><COL><COL><THEAD
><TR
><TH
>項目</TH
><TH
>値</TH
><TH
>説明</TH
></TR
></THEAD
><TBODY
><TR
><TD
>Pgpool-IIバージョン</TD
><TD
>4.0.2</TD
><TD
>-</TD
></TR
><TR
><TD
ROWSPAN="4"
>ポート番号</TD
><TD
>9999</TD
><TD
>Pgpool-IIが接続を受け付けるポート番号</TD
></TR
><TR
><TD
>9898</TD
><TD
>PCPプロセスが接続を受け付けるポート番号</TD
></TR
><TR
><TD
>9000</TD
><TD
>watchdogが接続を受け付けるポート番号</TD
></TR
><TR
><TD
>9694</TD
><TD
>Watchdogのハートビート信号を受信するUDPポート番号</TD
></TR
><TR
><TD
>設定ファイル</TD
><TD
>/etc/pgpool-II/pgpool.conf</TD
><TD
>Pgpool-IIの設定ファイル</TD
></TR
><TR
><TD
>Pgpool-II起動ユーザ</TD
><TD
>root</TD
><TD
>通常のユーザで<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を起動する場合の設定方法は<A
HREF="tutorial-watchdog-intro.html#TUTORIAL-WATCHDOG-START-STOP"
>項2.1.7</A
>をご参照ください。</TD
></TR
><TR
><TD
>Pgpool-II動作モード</TD
><TD
>ストリーミングレプリケーションモード</TD
><TD
>-</TD
></TR
><TR
><TD
>Watchdog機能</TD
><TD
>有効</TD
><TD
>ハードビート方式</TD
></TR
><TR
><TD
>自動起動</TD
><TD
>自動起動しない</TD
><TD
>-</TD
></TR
></TBODY
></TABLE
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-INSTALLATION"
>8.3.3. インストール</A
></H2
><P
>すべてのサーバに<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> 11.1と<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 4.0.2をRPMからインストールします。
      </P
><P
><SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>のインストールは<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>コミュニティのリポジトリを使います。
      </P
><PRE
CLASS="PROGRAMLISTING"
># yum install https://download.postgresql.org/pub/repos/yum/11/redhat/rhel-7-x86_64/pgdg-centos11-11-2.noarch.rpm
# yum install postgresql11 postgresql11-libs postgresql11-devel postgresql11-server
      </PRE
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>のインストールは<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>開発コミュニティが提供するYumリポジトリを用いてインストールします。
      </P
><PRE
CLASS="PROGRAMLISTING"
># yum install http://www.pgpool.net/yum/rpms/4.0/redhat/rhel-7-x86_64/pgpool-II-release-4.0-1.noarch.rpm
# yum install pgpool-II-pg11-*
      </PRE
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-PRE-SETUP"
>8.3.4. 事前設定</A
></H2
><P
></P
><UL
><LI
><P
><SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>プライマリサーバのみでストリーミングレプリケーションの設定を行います。設定方法についてはここでは省略します。
スタンバイサーバの設定は、プライマリが起動した状態で、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>のオンラインリカバリ機能を使って行います。
          </P
></LI
></UL
><P
></P
><UL
><LI
><P
>この設定の例ではアーカイブリカバリを行うように設定します。
          </P
><P
>まず、すべてのサーバにて<ACRONYM
CLASS="ACRONYM"
>WAL</ACRONYM
>を格納するディレクトリ<TT
CLASS="FILENAME"
>/var/lib/pgsql/archivedir</TT
>を事前に作成します。
          </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# su - postgres
[全サーバ]$ mkdir /var/lib/pgsql/archivedir
          </PRE
><P
>次に<TT
CLASS="LITERAL"
>server1</TT
>にて、設定ファイル<TT
CLASS="FILENAME"
>$PGDATA/postgresql.conf</TT
>を以下のように編集します。
          </P
><PRE
CLASS="PROGRAMLISTING"
>listen_addresses = '*'
archive_mode = on
archive_command = 'cp "%p" "/var/lib/pgsql/archivedir/%f"'
          </PRE
></LI
><LI
><P
>Pgpool-IIのヘルスチェック及びレプリケーションの遅延チェックでPostgreSQLのユーザを設定する必要があります。セキュリティ上の理由で、この設定例ではスーパーユーザを使わないようにします。
<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>のレプリケーションの遅延チェックとヘルスチェック用のユーザ<TT
CLASS="LITERAL"
>pgpool</TT
>を作成します。
また、<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>プライマリサーバ<TT
CLASS="LITERAL"
>server1</TT
>でレプリケーション専用ユーザ<TT
CLASS="LITERAL"
>repl</TT
>を作成します。
<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>4.0からSCRAM認証を利用できるようになりました。この設定例では、<TT
CLASS="LITERAL"
>scram-sha-256</TT
>認証方式を利用します。
まず、<TT
CLASS="LITERAL"
>password_encryption = 'scram-sha-256'</TT
>に変更してから、ユーザを登録します。
	</P
><DIV
CLASS="TABLE"
><A
NAME="EXAMPLE-CLUSTER-USER"
></A
><P
><B
>表 8-5. ユーザ</B
></P
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL><COL><COL><THEAD
><TR
><TH
>ユーザ名</TH
><TH
>パスワード</TH
><TH
>備考</TH
></TR
></THEAD
><TBODY
><TR
><TD
>repl</TD
><TD
>repl</TD
><TD
>PostgreSQLのレプリケーション専用ユーザ</TD
></TR
><TR
><TD
>pgpool</TD
><TD
>pgpool</TD
><TD
>Pgpool-IIのレプリケーション遅延チェック、ヘルスチェック専用ユーザ</TD
></TR
><TR
><TD
>postgres</TD
><TD
>postgres</TD
><TD
>オンラインリカバリを実行するユーザ</TD
></TR
></TBODY
></TABLE
></DIV
><PRE
CLASS="PROGRAMLISTING"
>[server1]# psql -U postgres -p 5432
postgres=# SET password_encryption = 'scram-sha-256';
postgres=# CREATE ROLE pgpool WITH LOGIN;
postgres=# CREATE ROLE repl WITH REPLICATION;
postgres=# \password pgpool
postgres=# \password repl
postgres=# \password postgres
          </PRE
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>注意: </B
><A
HREF="runtime-config-failover.html#GUC-DETACH-FALSE-PRIMARY"
>detach_false_primary</A
>を利用する予定がある場合、"pgpool" ロールは<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>のスーパーユーザーであるか、"pg_monitor" グループに所属する必要があります。
"pgpool"ユーザをそのグループに所属させるには以下のようにします。
          </P><PRE
CLASS="PROGRAMLISTING"
>GRANT pg_monitor TO pgpool;
	  </PRE
><P>
	    </P
></BLOCKQUOTE
></DIV
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>サーバと<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>バックエンドサーバが<TT
CLASS="LITERAL"
>192.168.137.0/24</TT
>のネットワークにあることを想定し、各ユーザが<TT
CLASS="LITERAL"
>scram-sha-256</TT
>認証方式で接続できるように、<TT
CLASS="FILENAME"
>pg_hba.conf</TT
>を編集しておきます。
          </P
><PRE
CLASS="PROGRAMLISTING"
>host    all             pgpool          192.168.137.0/24         scram-sha-256
host    all             all             0.0.0.0/0                scram-sha-256

host    replication     repl            192.168.137.0/24         scram-sha-256
          </PRE
></LI
><LI
><P
>自動フェイルオーバ、オンラインリカバリ機能を利用するために3台のサーバでは、<TT
CLASS="LITERAL"
>postgres</TT
>ユーザがパスワードなしで双方向に<TT
CLASS="COMMAND"
>ssh</TT
>接続できる状態にする必要があります。
          </P
></LI
><LI
><P
><TT
CLASS="LITERAL"
>repl</TT
>ユーザのパスワード入力なしで、ストリーミングレプリケーションとオンラインリカバリを行うために、すべてのサーバにて<TT
CLASS="LITERAL"
>postgres</TT
>ユーザのホームディレクト<TT
CLASS="FILENAME"
>/var/lib/pgsql</TT
> に<TT
CLASS="FILENAME"
>.pgpass</TT
>を作成・配置し、パーミッションを 600 に設定しておきます。
          </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# su - postgres
[全サーバ]$ vi /var/lib/pgsql/.pgpass
(以下を追加)
server1:5432:replication:repl:&lt;replユーザのパスワード&gt;
server2:5432:replication:repl:&lt;replユーザのパスワード&gt;
server3:5432:replication:repl:&lt;replユーザのパスワード&gt;
[全サーバ]$ chmod 600  /var/lib/pgsql/.pgpass
            </PRE
></LI
><LI
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>や<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>に接続する際には、ファイアーウォールによって目的のポートが開けられていなければなりません。<SPAN
CLASS="SYSTEMITEM"
>CentOS/RHEL7</SPAN
>の場合、以下のように設定します。
          </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# firewall-cmd --permanent --zone=public --add-service=postgresql
[全サーバ]# firewall-cmd --permanent --zone=public --add-port=9999/tcp --add-port=9898/tcp --add-port=9000/tcp  --add-port=9694/tcp
[全サーバ]# firewall-cmd --permanent --zone=public --add-port=9999/udp --add-port=9898/udp --add-port=9000/udp  --add-port=9694/udp
[全サーバ]# firewall-cmd --reload
            </PRE
></LI
></UL
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG"
>8.3.5. <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の設定</A
></H2
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-COMMON"
>8.3.5.1. 共通設定</A
></H3
><P
>以下の操作は<TT
CLASS="LITERAL"
>server1</TT
>, <TT
CLASS="LITERAL"
>server2</TT
>, <TT
CLASS="LITERAL"
>server3</TT
>での共通の設定です。
        </P
><P
>RPMからインストールした場合、すべての<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の設定ファイルは<TT
CLASS="FILENAME"
>/etc/pgpool-II</TT
>にあります。今回はストリーミングレプリケーションモードのテンプレートとして<TT
CLASS="FILENAME"
>pgpool.conf.sample-stream</TT
>サンプルファイルを使用します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# cp /etc/pgpool-II/pgpool.conf.sample-stream /etc/pgpool-II/pgpool.conf
        </PRE
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>が全てのIPアドレスから接続を受け付けるように、<A
HREF="runtime-config-connection.html#GUC-LISTEN-ADDRESSES"
>listen_addresses</A
>パラメータに<TT
CLASS="LITERAL"
>'*'</TT
>を設定します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>listen_addresses = '*'
        </PRE
><P
>レプリケーションの遅延チェックユーザ<A
HREF="runtime-streaming-replication-check.html#GUC-SR-CHECK-USER"
>sr_check_user</A
>にpgpoolユーザを設定します。
この設定例では、<A
HREF="runtime-streaming-replication-check.html#GUC-SR-CHECK-PASSWORD"
>sr_check_password</A
>は<TT
CLASS="FILENAME"
>pgpool.conf</TT
>に指定せず、<A
HREF="runtime-config-connection.html#GUC-POOL-PASSWD"
>pool_passwd</A
>ファイルに作成します。<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 4.0から、<A
HREF="runtime-streaming-replication-check.html#GUC-SR-CHECK-PASSWORD"
>sr_check_password</A
>が空白の場合、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>は空のパスワードを使用する前にまず<A
HREF="runtime-config-connection.html#GUC-POOL-PASSWD"
>pool_passwd</A
>ファイルから<A
HREF="runtime-streaming-replication-check.html#GUC-SR-CHECK-USER"
>sr_check_user</A
>に指定したユーザのパスワードを取得できるか試みます。
        </P
><PRE
CLASS="PROGRAMLISTING"
>sr_check_user = 'pgpool'
sr_check_password = ''
        </PRE
><P
>自動フェイルオーバのため、ヘルスチェックを有効にします。<A
HREF="runtime-config-health-check.html#GUC-HEALTH-CHECK-PERIOD"
>health_check_period</A
>のデフォルト値が0で、これはヘルスチェックが無効であることを意味します。
また、ネットワークが不安定な場合には、バックエンドが正常であるにも関わらず、ヘルスチェックに失敗し、フェイルオーバや縮退運転が発生してしまう可能性があります。そのようなヘルスチェックの誤検知を防止するため、ヘルスチェックのリトライ回数を<TT
CLASS="VARNAME"
>health_check_max_retries = 3</TT
> に設定しておきます。
<A
HREF="runtime-config-health-check.html#GUC-HEALTH-CHECK-USER"
>health_check_user</A
>、<A
HREF="runtime-config-health-check.html#GUC-HEALTH-CHECK-PASSWORD"
>health_check_password</A
>は前述の<A
HREF="runtime-streaming-replication-check.html#GUC-SR-CHECK-USER"
>sr_check_user</A
>、<A
HREF="runtime-streaming-replication-check.html#GUC-SR-CHECK-PASSWORD"
>sr_check_password</A
>と同様に設定します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>health_check_period = 5
                                   # Health check period
                                   # Disabled (0) by default
health_check_timeout = 30
                                   # Health check timeout
                                   # 0 means no timeout
health_check_user = 'pgpool'
health_check_password = ''

health_check_max_retries = 3
        </PRE
><P
>また、バックエンド情報を前述の<TT
CLASS="LITERAL"
>server1</TT
>、<TT
CLASS="LITERAL"
>server2</TT
>及び<TT
CLASS="LITERAL"
>server3</TT
>の設定に従って設定しておきます。複数バックエンドノードを定義する場合、以下のbackend_*などのパラメータ名の末尾にノードIDを表す数字を付加することで複数のバックエンドを指定することができます。
        </P
><PRE
CLASS="PROGRAMLISTING"
># - Backend Connection Settings -

backend_hostname0 = 'server1'
                                   # Host name or IP address to connect to for backend 0
backend_port0 = 5432
                                   # Port number for backend 0
backend_weight0 = 1
                                   # Weight for backend 0 (only in load balancing mode)
backend_data_directory0 = '/var/lib/pgsql/11/data'
                                   # Data directory for backend 0
backend_flag0 = 'ALLOW_TO_FAILOVER'
                                   # Controls various backend behavior
                                   # ALLOW_TO_FAILOVER or DISALLOW_TO_FAILOVER
backend_hostname1 = 'server2'
backend_port1 = 5432
backend_weight1 = 1
backend_data_directory1 = '/var/lib/pgsql/11/data'
backend_flag1 = 'ALLOW_TO_FAILOVER'

backend_hostname2 = 'server3'
backend_port2 = 5432
backend_weight2 = 1
backend_data_directory2 = '/var/lib/pgsql/11/data'
backend_flag2 = 'ALLOW_TO_FAILOVER'
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-FAILOVER"
>8.3.5.2. フェイルオーバの設定</A
></H3
><P
><SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>バックエンドノードがダウンした時に実行するスクリプトを<A
HREF="runtime-config-failover.html#GUC-FAILOVER-COMMAND"
>failover_command</A
>に設定します。
また、<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>サーバが3台の場合、プライマリノードのフェイルオーバ後に新しいプライマリからスレーブをリカバリするために<A
HREF="runtime-config-failover.html#GUC-FOLLOW-MASTER-COMMAND"
>follow_master_command</A
>も設定する必要があります。<A
HREF="runtime-config-failover.html#GUC-FOLLOW-MASTER-COMMAND"
>follow_master_command</A
>はプライマリノードのフェイルオーバ後に実行されます。<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>サーバが2台の場合、<A
HREF="runtime-config-failover.html#GUC-FOLLOW-MASTER-COMMAND"
>follow_master_command</A
>の設定は不要です。
        </P
><P
>それぞれの実行スクリプトの引数は、それぞれ実行時に<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>によってバックエンドの具体的な情報に置き換えられます。各引数の意味は<A
HREF="runtime-config-failover.html#GUC-FAILOVER-COMMAND"
>failover_command</A
>をご参照ください。
        </P
><PRE
CLASS="PROGRAMLISTING"
>failover_command = '/etc/pgpool-II/failover.sh %d %h %p %D %m %H %M %P %r %R'
follow_master_command = '/etc/pgpool-II/follow_master.sh %d %h %p %D %m %M %H %P %r %R'
      </PRE
><P
><TT
CLASS="FILENAME"
>/etc/pgpool-II/failover.sh</TT
>及び<TT
CLASS="FILENAME"
>/etc/pgpool-II/follow_master.sh</TT
>を作成し、実行権限を与えておきます。
      </P
><PRE
CLASS="PROGRAMLISTING"
># vi /etc/pgpool-II/failover.sh
# vi /etc/pgpool-II/follow_master.sh
# chmod +x /etc/pgpool-II/{failover.sh,follow_master.sh}
      </PRE
><P
></P
><UL
><LI
><P
>/etc/pgpool-II/failover.sh
          </P
><PRE
CLASS="PROGRAMLISTING"
>#!/bin/bash
# This script is run by failover_command.

set -o xtrace
exec &gt; &gt;(logger -i -p local1.info) 2&gt;&#38;1

# Special values:
#   %d = node id
#   %h = host name
#   %p = port number
#   %D = database cluster path
#   %m = new master node id
#   %H = hostname of the new master node
#   %M = old master node id
#   %P = old primary node id
#   %r = new master port number
#   %R = new master database cluster path
#   %% = '%' character

FAILED_NODE_ID="$1"
FAILED_NODE_HOST="$2"
FAILED_NODE_PORT="$3"
FAILED_NODE_PGDATA="$4"
NEW_MASTER_NODE_ID="$5"
NEW_MASTER_NODE_HOST="$6"
OLD_MASTER_NODE_ID="$7"
OLD_PRIMARY_NODE_ID="$8"
NEW_MASTER_NODE_PORT="$9"
NEW_MASTER_NODE_PGDATA="${10}"

PGHOME=/usr/pgsql-11

logger -i -p local1.info failover.sh: start: failed_node_id=$FAILED_NODE_ID old_primary_node_id=$OLD_PRIMARY_NODE_ID \
	failed_host=$FAILED_NODE_HOST new_master_host=$NEW_MASTER_NODE_HOST

# If standby node is down, skip failover.
if [ $FAILED_NODE_ID -ne $OLD_PRIMARY_NODE_ID ]; then
    logger -i -p local1.info failover.sh: Standby node is down. Skipping failover.
    exit 0
fi

# Promote standby node.
logger -i -p local1.info failover.sh: ssh: postgres@$NEW_MASTER_NODE_HOST pg_ctl promote
if [ $UID -eq 0 ]; then
    su postgres -c "ssh -T -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
    postgres@$NEW_MASTER_NODE_HOST ${PGHOME}/bin/pg_ctl -D ${NEW_MASTER_NODE_PGDATA} -w promote"
else
    ssh -T -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
    postgres@$NEW_MASTER_NODE_HOST ${PGHOME}/bin/pg_ctl -D ${NEW_MASTER_NODE_PGDATA} -w promote
fi

if [[ $? -ne 0 ]]; then
    logger -i -p local1.error failover.sh: new_master_host=$NEW_MASTER_NODE_HOST promote failed
    exit 1
fi

logger -i -p local1.info failover.sh: end: new_master_node_id=$NEW_MASTER_NODE_ID started as the primary node
exit 0
          </PRE
></LI
></UL
><P
></P
><UL
><LI
><P
>/etc/pgpool-II/follow_master.sh
          </P
><PRE
CLASS="PROGRAMLISTING"
>#!/bin/bash
# This script is run after failover_command to recover the slave from the new primary.

set -o xtrace
exec &gt; &gt;(logger -i -p local1.info) 2&gt;&#38;1

# special values:  %d = node id
#                  %h = host name
#                  %p = port number
#                  %D = database cluster path
#                  %m = new master node id
#                  %M = old master node id
#                  %H = new master node host name
#                  %P = old primary node id
#                  %R = new master database cluster path
#                  %r = new master port number
#                  %% = '%' character
FAILED_NODE_ID="$1"
FAILED_NODE_HOST="$2"
FAILED_NODE_PORT="$3"
FAILED_NODE_PGDATA="$4"
NEW_MASTER_NODE_ID="$5"
OLD_MASTER_NODE_ID="$6"
NEW_MASTER_NODE_HOST="$7"
OLD_PRIMARY_NODE_ID="$8"
NEW_MASTER_NODE_PORT="$9"
NEW_MASTER_NODE_PGDATA="${10}"

PGHOME=/usr/pgsql-11
ARCHIVEDIR=/var/lib/pgsql/archivedir
REPL_USER=repl
PCP_USER=pgpool
PGPOOL_PATH=/usr/bin
PCP_PORT=9898


# Recovery the slave from the new primary
logger -i -p local1.info follow_master.sh: start: pg_basebackup for $FAILED_NODE_ID

# Check the status of standby
ssh -T -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
    postgres@${FAILED_NODE_HOST} ${PGHOME}/bin/pg_ctl -w -D ${FAILED_NODE_PGDATA} status &#62;/dev/null 2&#62;&#38;1

# If slave is running, recover the slave from the new primary.
if [[ $? -eq 0 ]]; then

    # Execute pg_basebackup at slave
    ssh -T -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null postgres@${FAILED_NODE_HOST} "
        ${PGHOME}/bin/pg_ctl -w -m f -D ${FAILED_NODE_PGDATA} stop

        rm -rf ${FAILED_NODE_PGDATA}
        ${PGHOME}/bin/pg_basebackup -h ${NEW_MASTER_NODE_HOST} -U ${REPL_USER} -p ${NEW_MASTER_NODE_PORT} -D ${FAILED_NODE_PGDATA} -X stream -R

        if [[ $? -ne 0 ]]; then
            logger -i -p local1.error follow_master.sh: end: pg_basebackup failed
            exit 1
        fi
        rm -rf ${ARCHIVEDIR}/*
cat &gt;&gt; ${FAILED_NODE_PGDATA}/recovery.conf &lt;&lt; EOT
restore_command = 'scp ${NEW_MASTER_NODE_HOST}:${ARCHIVEDIR}/%f %p'
EOT
        $PGHOME/bin/pg_ctl -l /dev/null -w -D ${FAILED_NODE_PGDATA} start
    "

    if [[ $? -eq 0 ]]; then

        # Run pcp_attact_node to attach this slave to Pgpool-II.
        ${PGPOOL_PATH}/pcp_attach_node -w -h localhost -U ${PCP_USER} -p ${PCP_PORT} -n ${FAILED_NODE_ID}

        if [[ $? -ne 0 ]]; then
            logger -i -p local1.error follow_master.sh: end: pcp_attach_node failed
            exit 1
        fi
    else
        logger -i -p local1.error follow_master.sh: end: follow master failed
        exit 1
    fi

else
    logger -i -p local1.info follow_master.sh: failed_nod_id=${FAILED_NODE_ID} is not running. skipping follow master command.
    exit 0
fi

logger -i -p local1.info follow_master.sh: end: follow master is finished
exit 0
          </PRE
></LI
></UL
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-ONLINE-RECOVERY"
>8.3.5.3. オンラインリカバリの設定</A
></H3
><P
>続いて、オンラインリカバリを行うための<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>のユーザ名およびオンラインリカバリ時に呼び出されるコマンド<TT
CLASS="COMMAND"
>recovery_1st_stage</TT
>を設定します。
オンラインリカバリで実行される<CODE
CLASS="FUNCTION"
>pgpool_recovery</CODE
>関数は<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>のスーパーユーザ権限が必要なため、<TT
CLASS="VARNAME"
>recovery_user</TT
>にスーパーユーザを指定しなければなりません。ここでは、postrgesユーザを指定します。
オンラインリカバリ用のスクリプト<TT
CLASS="FILENAME"
>recovery_1st_stage</TT
>、<TT
CLASS="FILENAME"
>pgpool_remote_start</TT
>をプライマリサーバ(server1)のデータベースクラスタ配下に配置し、実行権限を与えておきます。
        </P
><PRE
CLASS="PROGRAMLISTING"
>recovery_user = 'postgres'
                                   # Online recovery user
recovery_password = ''
                                   # Online recovery password

recovery_1st_stage_command = 'recovery_1st_stage'
        </PRE
><PRE
CLASS="PROGRAMLISTING"
>[server1]# su - postgres
[server1]$ vi /var/lib/pgsql/11/data/recovery_1st_stage
[server1]$ vi /var/lib/pgsql/11/data/pgpool_remote_start
[server1]$ chmod +x /var/lib/pgsql/11/data/{recovery_1st_stage,pgpool_remote_start}
        </PRE
><P
></P
><UL
><LI
><P
>/var/lib/pgsql/11/data/recovery_1st_stage
            </P
><PRE
CLASS="PROGRAMLISTING"
>#!/bin/bash
# This script is run by recovery_1st_stage to recovery the slave from the primary.

set -o xtrace
exec &gt; &gt;(logger -i -p local1.info) 2&gt;&#38;1

PRIMARY_NODE_PGDATA="$1"
DEST_NODE_HOST="$2"
DEST_NODE_PGDATA="$3"
PRIMARY_NODE_PGPORT=$4

PRIMARY_NODE_HOST=$(hostname -s)
PGHOME=/usr/pgsql-11
ARCHIVEDIR=/var/lib/pgsql/archivedir
REPLUSER=repl


logger -i -p local1.info online_recovery.sh: start: pg_basebackup for $DEST_NODE_HOST

# Run pg_basebackup to recovery the slave from the primary
ssh -T -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null postgres@$DEST_NODE_HOST "
rm -rf $DEST_NODE_PGDATA
${PGHOME}/bin/pg_basebackup -h $PRIMARY_NODE_HOST -U $REPLUSER -p $PRIMARY_NODE_PGPORT -D $DEST_NODE_PGDATA -X stream -R
"
if [[ $? -ne 0 ]]; then
    logger -i -p local1.error online_recovery.sh: end: pg_basebackup failed. online recovery failed.
    exit 1
fi

ssh -T -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null postgres@$DEST_NODE_HOST "
rm -rf $ARCHIVEDIR/*
cat &gt;&gt; $DEST_NODE_PGDATA/recovery.conf &lt;&lt; EOT
restore_command = 'scp $PRIMARY_NODE_HOST:$archivedir/%f %p'
EOT
"

if [[ $? -ne 0 ]]; then
    logger -i -p local1.error online_recovery.sh: end: online recovery failed
    exit 1
else
    logger -i -p local1.info online_recovery.sh: end: online recovery is finished
    exit 0
fi
            </PRE
></LI
><LI
><P
>/var/lib/pgsql/11/data/pgpool_remote_start
          </P
><PRE
CLASS="PROGRAMLISTING"
>#!/bin/bash
# This script is run to start slave node after recovery.

set -o xtrace
exec &gt; &gt;(logger -i -p local1.info) 2&gt;&#38;1

PGHOME=/usr/pgsql-11
DEST_HOST="$1"
DEST_HOST_PGDATA="$2"


logger -i -p local1.info pgpool_remote_start: start: remote start PostgreSQL@$DEST_HOST

# Start slave node
ssh -T -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null postgres@$DEST_HOST $PGHOME/bin/pg_ctl -l /dev/null -w -D $DEST_HOST_PGDATA start

if [[ $? -ne 0 ]]; then
    logger -i -p local1.info  pgpool_remote_start: $DEST_HOST start failed.
    exit 1
fi

logger -i -p local1.info pgpool_remote_start: end: $DEST_HOST PostgreSQL started successfully.
          </PRE
></LI
></UL
><P
>また、オンラインリカバリ機能を使用するには、<CODE
CLASS="FUNCTION"
>pgpool_recovery</CODE
>、<CODE
CLASS="FUNCTION"
>pgpool_remote_start</CODE
>、<CODE
CLASS="FUNCTION"
>pgpool_switch_xlog</CODE
>という関数が必要になるので、<TT
CLASS="LITERAL"
>server1</TT
>のtemplate1に<CODE
CLASS="FUNCTION"
>pgpool_recovery</CODE
>をインストールしておきます。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[server1]# su - postgres
[server1]$ psql template1 -c "CREATE EXTENSION pgpool_recovery"
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-AUTH"
>8.3.5.4. クライアント認証の設定</A
></H3
><P
><A
HREF="example-cluster.html#EXAMPLE-CLUSTER-PRE-SETUP"
>事前設定</A
>の章で、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>と<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>の間に認証方式を<ACRONYM
CLASS="ACRONYM"
>scram-sha-256</ACRONYM
>に設定しました。この設定例では、クライアントと<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の間でも<ACRONYM
CLASS="ACRONYM"
>scram-sha-256</ACRONYM
>認証方式を利用し接続するように設定します。
<TT
CLASS="FILENAME"
>pgpool.conf</TT
>ファイル内の<A
HREF="runtime-config-health-check.html#GUC-HEALTH-CHECK-PASSWORD"
>health_check_password</A
>、<A
HREF="runtime-streaming-replication-check.html#GUC-SR-CHECK-PASSWORD"
>sr_check_password</A
>、<A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-PASSWORD"
>wd_lifecheck_password</A
>、<A
HREF="runtime-online-recovery.html#GUC-RECOVERY-PASSWORD"
>recovery_password</A
>にはAES256暗号化形式、平文形式しか指定できないので、ご注意ください。
<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>のクライアント認証の設定ファイルは<TT
CLASS="FILENAME"
>pool_hba.conf</TT
>と呼ばれ、RPMパッケージからインストールする場合、デフォルトでは<TT
CLASS="FILENAME"
>/etc/pgpool-II</TT
>配下にインストールされます。
デフォルトでは<TT
CLASS="FILENAME"
>pool_hba.conf</TT
>による認証は無効になっているので、<TT
CLASS="FILENAME"
>pgpool.conf</TT
>では以下の設定をonに変更します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>enable_pool_hba = on
        </PRE
><P
><TT
CLASS="FILENAME"
>pool_hba.conf</TT
>のフォーマットは<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>の<TT
CLASS="FILENAME"
>pg_hba.conf</TT
>とほとんど同じです。<TT
CLASS="LITERAL"
>pgpool</TT
>と<TT
CLASS="LITERAL"
>postgres</TT
>ユーザを<ACRONYM
CLASS="ACRONYM"
>scram-sha-256</ACRONYM
>認証に設定します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>host    all         pgpool           0.0.0.0/0          scram-sha-256
host    all         postgres         0.0.0.0/0          scram-sha-256
        </PRE
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>のクライアント認証で用いるデフォルトのパスワードファイル名はpool_passwdです。
<TT
CLASS="LITERAL"
>scram-sha-256</TT
>認証を利用する場合、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>はそれらのパスワードを復号化するために復号鍵が必要となります。全サーバで復号鍵ファイルをrootユーザのホームディレクトリ配下に作成します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# echo '任意の文字列' &#62; ~/.pgpoolkey 
[全サーバ]# chmod 600 ~/.pgpoolkey
        </PRE
><P
>「pg_enc -m -k /path/to/.pgpoolkey -u ユーザ名 -p」 コマンドを実行すると、ユーザ名と<TT
CLASS="LITERAL"
>AES256</TT
>で暗号化したパスワードのエントリが<A
HREF="runtime-config-connection.html#GUC-POOL-PASSWD"
>pool_passwd</A
>に登録されます。 
<A
HREF="runtime-config-connection.html#GUC-POOL-PASSWD"
>pool_passwd</A
> がまだ存在しなければ、<TT
CLASS="FILENAME"
>pgpool.conf</TT
>と同じディレクトリ内に作成されます。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# pg_enc -m -k /root/.pgpoolkey -u pgpool -p
db password: [pgpoolユーザのパスワード]
[全サーバ]# pg_enc -m -k /root/.pgpoolkey -u postgres -p
db password: [postgresユーザのパスワード]

# cat /etc/pgpool-II/pool_passwd 
pgpool:AESheq2ZMZjynddMWk5sKP/Rw==
postgres:AESHs/pWL5rtXy2IwuzroHfqg==
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-WATCHDOG"
>8.3.5.5. Watchdogの設定</A
></H3
><P
>デフォルトでは<TT
CLASS="LITERAL"
>watchdog</TT
>機能が無効のため、<TT
CLASS="LITERAL"
>server1</TT
>、<TT
CLASS="LITERAL"
>server2</TT
>及び<TT
CLASS="LITERAL"
>server3</TT
>で<TT
CLASS="LITERAL"
>watchdog</TT
>を有効にします。
        </P
><PRE
CLASS="PROGRAMLISTING"
>use_watchdog = on
        </PRE
><P
>アクティブ機が立ち上げる仮想IPをdelegate_IPに指定します。仮想 IP はまだ使われていないIPアドレスを指定してください。<TT
CLASS="LITERAL"
>server1</TT
>、<TT
CLASS="LITERAL"
>server2</TT
>及び<TT
CLASS="LITERAL"
>server3</TT
>の共通の設定です。
        </P
><PRE
CLASS="PROGRAMLISTING"
>delegate_IP = '192.168.137.150'
        </PRE
><P
>仮想IPの起動/停止、ARPリクエストの送信を行う設定パラメータ<A
HREF="runtime-watchdog-config.html#GUC-IF-UP-CMD"
>if_up_cmd</A
>、<A
HREF="runtime-watchdog-config.html#GUC-IF-DOWN-CMD"
>if_down_cmd</A
>、<A
HREF="runtime-watchdog-config.html#GUC-ARPING-CMD"
>arping_cmd</A
>に、ネットワーク環境に合わせてネットワークインターフェース名を設定します。
今回の例で使ったネットワークインターフェースは「enp0s8」となっています。
        </P
><PRE
CLASS="PROGRAMLISTING"
>if_up_cmd = 'ip addr add $_IP_$/24 dev enp0s8 label enp0s8:0'
                                    # startup delegate IP command
if_down_cmd = 'ip addr del $_IP_$/24 dev enp0s8'
                                    # shutdown delegate IP command
arping_cmd = 'arping -U $_IP_$ -w 1 -I enp0s8'
                                    # arping command
        </PRE
><P
>ipコマンドやarpingコマンドのパスがデフォルトのパスと異なる場合、環境に合わせて<A
HREF="runtime-watchdog-config.html#GUC-IF-CMD-PATH"
>if_cmd_path</A
>や<A
HREF="runtime-watchdog-config.html#GUC-ARPING-PATH"
>arping_path</A
>を設定しておいてください。
        </P
><PRE
CLASS="PROGRAMLISTING"
>if_cmd_path = '/sbin'
                                    # path to the directory where if_up/down_cmd exists
arping_path = '/usr/sbin'
                                    # arping command path
        </PRE
><P
>各watchdog が稼働するサーバ情報を設定しておきます。
        </P
><P
></P
><UL
><LI
><P
><TT
CLASS="LITERAL"
>server1</TT
>の場合
            </P
><PRE
CLASS="PROGRAMLISTING"
>wd_hostname = 'server1'
wd_port = 9000
            </PRE
></LI
><LI
><P
><TT
CLASS="LITERAL"
>server2</TT
>の場合
            </P
><PRE
CLASS="PROGRAMLISTING"
>wd_hostname = 'server2'
wd_port = 9000
            </PRE
></LI
><LI
><P
><TT
CLASS="LITERAL"
>server3</TT
>の場合
            </P
><PRE
CLASS="PROGRAMLISTING"
>wd_hostname = 'server3'
wd_port = 9000
            </PRE
></LI
></UL
><P
>各監視対象の<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>サーバ情報を設定しておきます。
        </P
><P
></P
><UL
><LI
><P
><TT
CLASS="LITERAL"
>server1</TT
>の場合
            </P
><PRE
CLASS="PROGRAMLISTING"
># - Other pgpool Connection Settings -

other_pgpool_hostname0 = 'server2'
                                    # Host name or IP address to connect to for other pgpool 0
                                    # (change requires restart)
other_pgpool_port0 = 9999
                                    # Port number for other pgpool 0
                                    # (change requires restart)
other_wd_port0 = 9000
                                    # Port number for other watchdog 0
                                    # (change requires restart)
other_pgpool_hostname1 = 'server3'
other_pgpool_port1 = 9999
other_wd_port1 = 9000
            </PRE
></LI
><LI
><P
><TT
CLASS="LITERAL"
>server2</TT
>の場合
            </P
><PRE
CLASS="PROGRAMLISTING"
># - Other pgpool Connection Settings -

other_pgpool_hostname0 = 'server1'
                                    # Host name or IP address to connect to for other pgpool 0
                                    # (change requires restart)
other_pgpool_port0 = 9999
                                    # Port number for other pgpool 0
                                    # (change requires restart)
other_wd_port0 = 9000
                                    # Port number for other watchdog 0
                                    # (change requires restart)
other_pgpool_hostname1 = 'server3'
other_pgpool_port1 = 9999
other_wd_port1 = 9000
            </PRE
></LI
><LI
><P
><TT
CLASS="LITERAL"
>server3</TT
>の場合
            </P
><PRE
CLASS="PROGRAMLISTING"
># - Other pgpool Connection Settings -

other_pgpool_hostname0 = 'server1'
                                    # Host name or IP address to connect to for other pgpool 0
                                    # (change requires restart)
other_pgpool_port0 = 9999
                                    # Port number for other pgpool 0
                                    # (change requires restart)
other_wd_port0 = 9000
                                    # Port number for other watchdog 0
                                    # (change requires restart)
other_pgpool_hostname1 = 'server2'
other_pgpool_port1 = 9999
other_wd_port1 = 9000
            </PRE
></LI
></UL
><P
>ハートビート信号の送信先のホスト名とポート番号を指定します。
        </P
><P
></P
><UL
><LI
><P
><TT
CLASS="LITERAL"
>server1</TT
>の場合
            </P
><PRE
CLASS="PROGRAMLISTING"
>heartbeat_destination0 = 'server2'
                                    # Host name or IP address of destination 0
                                    # for sending heartbeat signal.
                                    # (change requires restart)
heartbeat_destination_port0 = 9694
                                    # Port number of destination 0 for sending
                                    # heartbeat signal. Usually this is the
                                    # same as wd_heartbeat_port.
                                    # (change requires restart)
heartbeat_device0 = ''
                                    # Name of NIC device (such like 'eth0')
                                    # used for sending/receiving heartbeat
                                    # signal to/from destination 0.
                                    # This works only when this is not empty
                                    # and pgpool has root privilege.
                                    # (change requires restart)

heartbeat_destination1 = 'server3'
heartbeat_destination_port1 = 9694
heartbeat_device1 = ''

            </PRE
></LI
><LI
><P
><TT
CLASS="LITERAL"
>server2</TT
>の場合
            </P
><PRE
CLASS="PROGRAMLISTING"
>heartbeat_destination0 = 'server1'
                                    # Host name or IP address of destination 0
                                    # for sending heartbeat signal.
                                    # (change requires restart)
heartbeat_destination_port0 = 9694
                                    # Port number of destination 0 for sending
                                    # heartbeat signal. Usually this is the
                                    # same as wd_heartbeat_port.
                                    # (change requires restart)
heartbeat_device0 = ''
                                    # Name of NIC device (such like 'eth0')
                                    # used for sending/receiving heartbeat
                                    # signal to/from destination 0.
                                    # This works only when this is not empty
                                    # and pgpool has root privilege.
                                    # (change requires restart)

heartbeat_destination1 = 'server3'
heartbeat_destination_port1 = 9694
heartbeat_device1 = ''

            </PRE
></LI
><LI
><P
><TT
CLASS="LITERAL"
>server3</TT
>の場合
            </P
><PRE
CLASS="PROGRAMLISTING"
>heartbeat_destination0 = 'server1'
                                    # Host name or IP address of destination 0
                                    # for sending heartbeat signal.
                                    # (change requires restart)
heartbeat_destination_port0 = 9694
                                    # Port number of destination 0 for sending
                                    # heartbeat signal. Usually this is the
                                    # same as wd_heartbeat_port.
                                    # (change requires restart)
heartbeat_device0 = ''
                                    # Name of NIC device (such like 'eth0')
                                    # used for sending/receiving heartbeat
                                    # signal to/from destination 0.
                                    # This works only when this is not empty
                                    # and pgpool has root privilege.
                                    # (change requires restart)

heartbeat_destination1 = 'server2'
heartbeat_destination_port1 = 9694
heartbeat_device1 = ''
            </PRE
></LI
></UL
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-SYSCONFIG"
>8.3.5.6. /etc/sysconfig/pgpoolの設定</A
></H3
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を起動時に<TT
CLASS="FILENAME"
>pgpool_status</TT
>ファイルを無視させたい場合、<TT
CLASS="FILENAME"
>/etc/sysconfig/pgpool</TT
>の起動オプションOPTSに「-D」を追加します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# vi /etc/sysconfig/pgpool 
(...省略...)
OPTS=" -D -n"
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-LOG"
>8.3.5.7. ログの設定</A
></H3
><P
>この例では、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>のログ出力は<TT
CLASS="LITERAL"
>syslog</TT
>を利用するように設定します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>log_destination = 'syslog'
                                   # Where to log
                                   # Valid values are combinations of stderr,
                                   # and syslog. Default to stderr.

syslog_facility = 'LOCAL1'
                                   # Syslog local facility. Default to LOCAL0
        </PRE
><P
>全サーバではログファイルを作成します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# mkdir /var/log/pgpool-II
[全サーバ]# touch /var/log/pgpool-II/pgpool.log
        </PRE
><P
>次に<TT
CLASS="LITERAL"
>syslog</TT
>の設定ファイルを以下のように編集します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# vi /etc/rsyslog.conf
...(省略)...
*.info;mail.none;authpriv.none;cron.none;LOCAL1.none    /var/log/messages
LOCAL1.*                                                /var/log/pgpool-II/pgpool.log
        </PRE
><P
>また、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>に関して<TT
CLASS="FILENAME"
>/var/log/messages</TT
>と同様のログローテーションを行うように、logrotateの設定を以下のように行います。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# vi /etc/logrotate.d/syslog
...(省略)...
/var/log/messages
/var/log/pgpool-II/pgpool.log
/var/log/secure
        </PRE
><P
>設定が終わったら、rsyslogサービスを再起動します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# systemctl restart rsyslog
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-PCP"
>8.3.5.8. PCPコマンドの設定</A
></H3
><P
><TT
CLASS="LITERAL"
>PCP</TT
>コマンドを使用するにはユーザ認証が必要になるので、ユーザ名と<TT
CLASS="LITERAL"
>md5</TT
>ハッシュに変換されたパスワードを<TT
CLASS="FILENAME"
>pcp.conf</TT
>ファイルに設定します。
ここではユーザ名に<TT
CLASS="LITERAL"
>pgpool</TT
>を使用し、以下のコマンドを実行することで、&lt;ユーザ名:ハッシュ化されたパスワード&gt;が<TT
CLASS="FILENAME"
>/etc/pgpool-II/pcp.conf</TT
>に追加されます。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# echo 'pgpool:'`pg_md5 PCPコマンドパスワード` &#62;&#62; /etc/pgpool-II/pcp.conf
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-PCPPASS"
>8.3.5.9. .pcppassの設定</A
></H3
><P
>前述の<TT
CLASS="LITERAL"
>follow_master_command</TT
>のスクリプトでパスワード入力なしで<TT
CLASS="LITERAL"
>PCP</TT
>コマンドを実行できるように、すべてのサーバで<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の起動ユーザのホームディレクトリに<TT
CLASS="FILENAME"
>.pcppass</TT
>を作成します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[全サーバ]# echo 'localhost:9898:pgpool:pgpool' &#62; ~/.pcppass
[全サーバ]# chmod 600 ~/.pcppass
        </PRE
><P
>ここで、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の設定は完了です。
        </P
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-START-STOP"
>8.3.6. システムの起動と停止</A
></H2
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の設定が完了したら、次に<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を起動します。<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を起動する前に、バックエンドの<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>をあらかじめ起動する必要があります。また、<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>を停止する場合、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を先に停止する必要があります。
      </P
><P
></P
><UL
><LI
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の起動
          </P
><P
>前述の<A
HREF="example-cluster.html#EXAMPLE-CLUSTER-PRE-SETUP"
>事前設定</A
>の章で<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の自動起動が設定済なので、ここでシステム全体を再起動するか、以下のコマンドを実行してください。
          </P
><PRE
CLASS="PROGRAMLISTING"
># systemctl start pgpool.service
          </PRE
></LI
><LI
><P
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の停止
          </P
><PRE
CLASS="PROGRAMLISTING"
># systemctl stop pgpool.service
          </PRE
></LI
></UL
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-TRY"
>8.3.7. 動作確認</A
></H2
><P
>これから、動作確認を行います。まず、<TT
CLASS="LITERAL"
>server1</TT
>、<TT
CLASS="LITERAL"
>server2</TT
>、<TT
CLASS="LITERAL"
>server3</TT
>で以下のコマンドで<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を起動します。
      </P
><PRE
CLASS="PROGRAMLISTING"
># systemctl start pgpool.service
      </PRE
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-TRY-STANDBY"
>8.3.7.1. PostgreSQL スタンバイサーバを構築</A
></H3
><P
>まず、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>のオンラインリカバリ機能を利用し、スタンバイサーバを構築します。<TT
CLASS="COMMAND"
>pcp_recovery_node</TT
>コマンドで実行される<TT
CLASS="VARNAME"
>recovery_1st_stage_command</TT
>パラメータに指定した<TT
CLASS="FILENAME"
>recovery_1st_stage</TT
>と<TT
CLASS="FILENAME"
>pgpool_remote_start</TT
>スプリクトが実行されるので、この 2つのスクリプトが現在稼働中のプライマリサーバ<TT
CLASS="LITERAL"
>server1</TT
>のデータベースクラスタの下に存在することを確認します。
        </P
><PRE
CLASS="PROGRAMLISTING"
># pcp_recovery_node -h 192.168.137.150 -p 9898 -U pgpool -n 1
Password: 
pcp_recovery_node -- Command Successful

# pcp_recovery_node -h 192.168.137.150 -p 9898 -U pgpool -n 2
Password: 
pcp_recovery_node -- Command Successful
      </PRE
><P
><TT
CLASS="LITERAL"
>server2</TT
>と<TT
CLASS="LITERAL"
>server3</TT
>の<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>がスタンバイとして起動されていることを確認します。
      </P
><PRE
CLASS="PROGRAMLISTING"
># psql -h 192.168.137.150 -p 9999 -U pgpool postgres -c "show pool_nodes"
ユーザ pgpool のパスワード: 
 node_id | hostname | port | status | lb_weight |  role   | select_cnt | load_balance_node | replication_delay | last_status_change  
---------+----------+------+--------+-----------+---------+------------+-------------------+-------------------+---------------------
 0       | server1  | 5432 | up     | 0.333333  | primary | 0          | false             | 0                 | 2019-02-18 11:26:31
 1       | server2  | 5432 | up     | 0.333333  | standby | 0          | true              | 0                 | 2019-02-18 11:27:49
 2       | server3  | 5432 | up     | 0.333333  | standby | 0          | false             | 0                 | 2019-02-18 11:27:49
(3 行)
      </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-TRY-WATCHDOG"
>8.3.7.2. watchdogアクティブ/スタンバイの切り替え</A
></H3
><P
><TT
CLASS="COMMAND"
>pcp_watchdog_info</TT
>で<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>の<SPAN
CLASS="APPLICATION"
>watchdog</SPAN
>の情報を確認します。最初に起動した<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>が「MASTER」になります。
        </P
><PRE
CLASS="PROGRAMLISTING"
># pcp_watchdog_info -h 192.168.137.150 -p 9898 -U pgpool
Password: 
3 YES server1:9999 Linux server1 server1

server1:9999 Linux server1 server1 9999 9000 4 MASTER  #最初に起動されたサーバがMASTERになる
server2:9999 Linux server2 server2 9999 9000 7 STANDBY #スタンバイとして稼働
server3:9999 Linux server3 server3 9999 9000 7 STANDBY #スタンバイとして稼働
        </PRE
><P
>アクティブである<TT
CLASS="LITERAL"
>server1</TT
>の<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を停止し、<TT
CLASS="LITERAL"
>server2</TT
>または<TT
CLASS="LITERAL"
>server3</TT
>がスタンバイからアクティブに昇格することを確認します。<TT
CLASS="LITERAL"
>server1</TT
>を停止する方法は<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を停止する、またはマシンをシャットダウンします。ここでは、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を停止します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[server1]# systemctl stop pgpool.service

# pcp_watchdog_info -p 9898 -h 192.168.137.150 -U pgpool
Password: 
3 YES server2:9999 Linux server2 server2

server2:9999 Linux server2 server2 9999 9000 4 MASTER     #server2がアクティブに昇格
server1:9999 Linux server1 server1 9999 9000 10 SHUTDOWN  #server1が停止された
server3:9999 Linux server3 server3 9999 9000 7 STANDBY    #スタンバイとして稼働
        </PRE
><P
>先ほど停止した<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>を再起動し、スタンバイとして起動したことを確認します。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[server1]# systemctl start pgpool.service

[server1]# pcp_watchdog_info -p 9898 -h 192.168.137.150 -U pgpool
Password: 
3 YES server2:9999 Linux server2 server2

server2:9999 Linux server2 server2 9999 9000 4 MASTER
server1:9999 Linux server1 server1 9999 9000 7 STANDBY
server3:9999 Linux server3 server3 9999 9000 7 STANDBY
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-TRY-FAILOVER"
>8.3.7.3. 自動フェイルオーバ</A
></H3
><P
><TT
CLASS="COMMAND"
>psql</TT
>で仮想IPに接続し、バックエンドの情報を確認します。
        </P
><PRE
CLASS="PROGRAMLISTING"
># psql -h 192.168.137.150 -p 9999 -U pgpool postgres -c "show pool_nodes"
ユーザ pgpool のパスワード: 
 node_id | hostname | port | status | lb_weight |  role   | select_cnt | load_balance_node | replication_delay | last_status_change  
---------+----------+------+--------+-----------+---------+------------+-------------------+-------------------+---------------------
 0       | server1  | 5432 | up     | 0.333333  | primary | 0          | false             | 0                 | 2019-02-18 13:08:02
 1       | server2  | 5432 | up     | 0.333333  | standby | 0          | false             | 0                 | 2019-02-18 13:21:56
 2       | server3  | 5432 | up     | 0.333333  | standby | 0          | true              | 0                 | 2019-02-18 13:21:56
(3 行)
        </PRE
><P
>次にプライマリである<TT
CLASS="LITERAL"
>server1</TT
>の<SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>を停止し、フェイルオーバするかどうか確認してみます。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[server1]$ pg_ctl -D /var/lib/pgsql/11/data -m immediate stop
        </PRE
><P
><TT
CLASS="LITERAL"
>ノード1</TT
>を停止後、フェイルオーバが発生し、<TT
CLASS="LITERAL"
>server2</TT
>がプライマリに昇格したことを確認します。
        </P
><PRE
CLASS="PROGRAMLISTING"
># psql -h 192.168.137.150 -p 9999 -U pgpool postgres -c "show pool_nodes"
ユーザ pgpool のパスワード: 
 node_id | hostname | port | status | lb_weight |  role   | select_cnt | load_balance_node | replication_delay | last_status_change  
---------+----------+------+--------+-----------+---------+------------+-------------------+-------------------+---------------------
 0       | server1  | 5432 | down   | 0.333333  | standby | 0          | false             | 0                 | 2019-02-18 13:22:25
 1       | server2  | 5432 | up     | 0.333333  | primary | 0          | true              | 0                 | 2019-02-18 13:22:25
 2       | server3  | 5432 | up     | 0.333333  | standby | 0          | false             | 0                 | 2019-02-18 13:22:28
(3 行)
        </PRE
><P
><TT
CLASS="LITERAL"
>server3</TT
>が新しいプライマリ<TT
CLASS="LITERAL"
>server2</TT
>のスタンバイとして起動されています。
        </P
><PRE
CLASS="PROGRAMLISTING"
>[server3]# psql -h server3 -p 5432 -U pgpool postgres -c "select pg_is_in_recovery()"
ユーザ pgpool のパスワード: 
 pg_is_in_recovery 
-------------------
 t
(1 行)

[server2]# su - postgres
$ psql
postgres=# select pg_is_in_recovery();
 pg_is_in_recovery 
-------------------
 f
(1 行)

postgres=# select * from pg_stat_replication;
-[ RECORD 1 ]----+------------------------------
pid              | 11915
usesysid         | 16385
usename          | repl
application_name | walreceiver
client_addr      | 192.168.137.103
client_hostname  | 
client_port      | 37834
backend_start    | 2019-02-18 13:22:27.472038+09
backend_xmin     | 
state            | streaming
sent_lsn         | 0/8E000060
write_lsn        | 0/8E000060
flush_lsn        | 0/8E000060
replay_lsn       | 0/8E000060
write_lag        | 
flush_lag        | 
replay_lag       | 
sync_priority    | 0
sync_state       | async
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-TRY-ONLINE-RECOVERY"
>8.3.7.4. オンラインリカバリ</A
></H3
><P
>次に、<SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>のオンラインリカバリ機能を利用し、先ほど停止した旧プライマリサーバをスタンバイとして復旧させます。<TT
CLASS="COMMAND"
>pcp_recovery_node</TT
>コマンドで実行される<TT
CLASS="VARNAME"
>recovery_1st_stage_command</TT
>パラメータに指定した<TT
CLASS="FILENAME"
>recovery_1st_stage</TT
>と<TT
CLASS="FILENAME"
>pgpool_remote_start</TT
>スプリクトが現在稼働中のプライマリサーバ<TT
CLASS="LITERAL"
>server2</TT
>のデータベースクラスタの下に存在することを確認します。
        </P
><PRE
CLASS="PROGRAMLISTING"
># pcp_recovery_node -h 192.168.137.150 -p 9898 -U pgpool -n 0
Password: 
pcp_recovery_node -- Command Successful
        </PRE
><P
><TT
CLASS="LITERAL"
>ノード1</TT
>がスタンバイとして起動されたことを確認します。
        </P
><PRE
CLASS="PROGRAMLISTING"
># psql -h 192.168.137.150 -p 9999 -U pgpool postgres -c "show pool_nodes"
ユーザ pgpool のパスワード:
 node_id | hostname | port | status | lb_weight |  role   | select_cnt | load_balance_node | replication_delay | last_status_change  
---------+----------+------+--------+-----------+---------+------------+-------------------+-------------------+---------------------
 0       | server1  | 5432 | up     | 0.333333  | standby | 0          | false             | 0                 | 2019-02-18 13:27:44
 1       | server2  | 5432 | up     | 0.333333  | primary | 0          | false             | 0                 | 2019-02-18 13:22:25
 2       | server3  | 5432 | up     | 0.333333  | standby | 0          | true              | 0                 | 2019-02-18 13:22:28
(3 行)
        </PRE
><P
>以上で、動作確認が完了です。
        </P
></DIV
></DIV
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="example-watchdog.html"
ACCESSKEY="P"
>前のページ</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.html"
ACCESSKEY="H"
>ホーム</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="example-aws.html"
ACCESSKEY="N"
>次のページ</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Watchdogの設定例</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="example-configs.html"
ACCESSKEY="U"
>上に戻る</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>AWS設定の例</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>