<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Release 4.1.0</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"><LINK
REV="MADE"
HREF="mailto:pgsql-docs@postgresql.org"><LINK
REL="HOME"
TITLE="pgpool-II 4.2devel Documentation"
HREF="index.html"><LINK
REL="UP"
TITLE="Release Notes"
HREF="release.html"><LINK
REL="PREVIOUS"
TITLE="Release 4.1.1"
HREF="release-4-1-1.html"><LINK
REL="NEXT"
TITLE="Release 4.0.9"
HREF="release-4-0-9.html"><LINK
REL="STYLESHEET"
TYPE="text/css"
HREF="stylesheet.css"><META
HTTP-EQUIV="Content-Type"
CONTENT="text/html; charset=ISO-8859-1"><META
NAME="creation"
CONTENT="2020-08-14T12:08:25"></HEAD
><BODY
CLASS="SECT1"
><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="4"
ALIGN="center"
VALIGN="bottom"
><A
HREF="index.html"
>pgpool-II 4.2devel Documentation</A
></TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
TITLE="Release 4.1.1"
HREF="release-4-1-1.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
HREF="release.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="60%"
ALIGN="center"
VALIGN="bottom"
>Appendix A. Release Notes</TD
><TD
WIDTH="20%"
ALIGN="right"
VALIGN="top"
><A
TITLE="Release 4.0.9"
HREF="release-4-0-9.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="RELEASE-4-1-0"
>A.3. Release 4.1.0</A
></H1
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Release Date: </B
>2019-10-xx</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="AEN9882"
>A.3.1. Overview</A
></H2
><P
>   This version implements long awaited features including
   <A
HREF="runtime-config-load-balancing.html#GUC-STATEMENT-LEVEL-LOAD-BALANCE"
>statement_level_load_balance</A
>
    and <A
HREF="runtime-config-failover.html#GUC-AUTO-FAILBACK"
>auto_failback</A
>. Also it enhances number
     of areas related to performance. Finally it
     imports <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> 12's new SQL
     parser.
  </P
><P
>   Major enhancements in <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 4.1 include:
  </P
><P
></P
><UL
><LI
><P
>     Statement level load
     balancing. Previously <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
     only allows session level load balancing. This version
     allows to use <TT
CLASS="LITERAL"
>statement level load
      balancing</TT
>, which is useful for frontends
     permanently connecting
     to <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> but want to use
     existing standby server resources.
    </P
></LI
><LI
><P
>     Auto failback allows to automatically attach streaming
     replication standby servers, which are considered safe
     enough to failback.
    </P
></LI
><LI
><P
>     Enhance performance in number of areas.
     <P
></P
></P><UL
><LI
><P
>	Shared relation cache allows to reuse relation cache
	among sessions to reduce internal queries
	against <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> system
	catalogs.
       </P
></LI
><LI
><P
>	Have separate SQL parser for DML statements to
	eliminate unnecessary parsing effort.
       </P
></LI
><LI
><P
>	Load balancing control for specific queries.
       </P
></LI
></UL
><P>
    </P
></LI
><LI
><P
>     Import PostgreSQL 12 SQL parser.
    </P
></LI
></UL
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="MIGRATION-TO-VERSION-4-1"
>A.3.2. Migration to Version 4.1</A
></H2
><P
>   Version 4.1 contains some changes that may affect compatibility
   with previous releases. Observe the following incompatibilities:
  </P
><P
></P
><UL
><LI
><P
>     Add <TT
CLASS="VARNAME"
>replication_state</TT
> and
     <TT
CLASS="VARNAME"
>replication_sync_state</TT
> columns
     of <A
HREF="sql-show-pool-nodes.html"
>SHOW POOL NODES</A
> and friends. (Tatsuo
      Ishii)
    </P
><P
>     This allows to show important information from
     <TT
CLASS="COMMAND"
>pg_stat_replication</TT
>, which is available
     from <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> 9.1 (also with
     <TT
CLASS="VARNAME"
>replication_state_sync</TT
>. it's only
     available since 9.2 however).  For this purpose
     new <A
HREF="runtime-config-backend-settings.html#GUC-BACKEND-APPLICATION-NAME"
>backend_application_name</A
> parameter is
      added to each backend_host configuration parameters.
      <TT
CLASS="COMMAND"
>pg_stat_replication</TT
> is called from
      streaming replication delay checking process. So
      if <A
HREF="runtime-streaming-replication-check.html#GUC-SR-CHECK-PERIOD"
>sr_check_period</A
> is 0, those new columns
       are not available.
    </P
><P
>     Also <A
HREF="pcp-node-info.html"
>pcp_node_info</A
>
      and <A
HREF="pgpool-adm-pcp-node-info.html"
>pgpool_adm_pcp_node_info</A
> function are
       modified.
    </P
></LI
><LI
><P
>     Add parameter <A
HREF="runtime-watchdog-config.html#GUC-ENABLE-CONSENSUS-WITH-HALF-VOTES"
>enable_consensus_with_half_votes</A
> to configure
     majority rule calculations. (Muhammad Usama, Tatsuo Ishii)
    </P
><P
>     This changes the behavior of the decision of quorum existence and
     failover consensus on even number (i.e. 2, 4, 6...) of watchdog
     clusters. Odd number of clusters (3, 5, 7...) are not
     affected. When this parameter is off (the default), a 2 node
     watchdog cluster needs to have both 2 nodes are alive to have a
     quorum. If the quorum does not exist and 1 node goes down, then
     1) VIP will be lost, 2) failover script is not executed and 3)
     no watchdog master exists. Especially #2 could be troublesome
     because no new primary <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>
     exists if existing primary goes down. Probably 2 node watchdog
     cluster users want to turn on this parameter to keep the existing
     behavior. On the other hand 4 or more even number of watchdog
     cluster users will benefit from this parameter is off because now
     it prevents possible split brain when a half of watchdog nodes go
     down.
    </P
></LI
><LI
><P
>     If installing from RPMs, by default <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
     is started by <TT
CLASS="LITERAL"
>postgres</TT
> user. (Bo Peng)
    </P
><P
>     Because of the security reason, the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> default
     startup user is changed to <TT
CLASS="LITERAL"
>postgres</TT
> user.
    </P
><P
>     If installing from RPMs, <TT
CLASS="LITERAL"
>postrges</TT
> user will be allowed to
     run <TT
CLASS="VARNAME"
>if_up/down_cmd</TT
> and <TT
CLASS="VARNAME"
>arping_cmd</TT
>
     with <TT
CLASS="COMMAND"
>sudo</TT
> without a password.
     If <TT
CLASS="VARNAME"
>if_up/down_cmd</TT
> or <TT
CLASS="VARNAME"
>arping_cmd</TT
> starts with "/",
     the setting specified in <TT
CLASS="VARNAME"
>if_cmd_path</TT
> or <TT
CLASS="VARNAME"
>arping_path</TT
>
     will be ignored.
    </P
></LI
><LI
><P
>     Down grade LOG to DEBUG5 in sent message module. (Tatsuo Ishii)
    </P
></LI
></UL
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="AEN9952"
>A.3.3. Major Enhancements</A
></H2
><P
></P
><UL
><LI
><P
>     Allow to use statement level load balancing. (Bo Peng)
    </P
><P
>     This feature enables selecting load balancing node per
     statement.  The current feature for load balancing, the load
     balancing node is decided at the session start time and will
     not be changed until the session ends.  When set to
     <A
HREF="runtime-config-load-balancing.html#GUC-STATEMENT-LEVEL-LOAD-BALANCE"
>statement_level_load_balance</A
> = on,
      the load balancing node is decided for each read query.  For
      example, in applications that use connection pooling remain
      connections open to the backend server, because the session
      may be held for a long time, the load balancing node does
      not change until the session ends.  In such applications,
      when statement_level_load_balance is enabled, it is possible
      to decide load balancing node per query, not per session.
    </P
></LI
><LI
><P
>     Add <A
HREF="runtime-config-failover.html#GUC-AUTO-FAILBACK"
>auto_failback</A
> (Takuma Hoshiai).
    </P
><P
>     This allows to reattach backend node automatically that is
     in DOWN status but actually it is running normally.
    </P
><P
>     To use this feature it is required
     that <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> is 9.1 or later
     and new configuration
     variable <TT
CLASS="VARNAME"
>auto_failback</TT
> is
     enabled. Also <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> must be
     operating in streaming-replication mode, with sr_check and
     health_check are
     enabled. <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> calls
     pg_stat_replication on
     the <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> primary server to
     make sure that the standby node in question is running and
     receiving replication stream from the primary server.
    </P
><P
>     This feature is useful in the case that a standby server
     fails over due to a temporary network failure.
    </P
></LI
><LI
><P
>     Add new <A
HREF="runtime-misc.html#GUC-ENABLE-SHARED-RELCACHE"
>enable_shared_relcache</A
>
      parameter. (Takuma Hoshiai)
    </P
><P
>     The relation cache were stored in local cache of child
     processes, so all child processes executed same query to get
     relation cache.  If <A
HREF="runtime-misc.html#GUC-ENABLE-SHARED-RELCACHE"
>enable_shared_relcache</A
>
      is on, the relation cache is stored in memory cache and all
      child process share it.  It will expect to reduce the load
      that same query is executed.
    </P
></LI
><LI
><P
>     Add new parameter <A
HREF="runtime-misc.html#GUC-CHECK-TEMP-TABLE"
>check_temp_table</A
> to
      check temporary tables. (Tatsuo Ishii)
    </P
><P
>     Checking temporary tables is slow because it needs to lookup
     system catalogs. To eliminate the lookup, new method to
     trace <TT
CLASS="COMMAND"
>CREATE TEMP TABLE/DROP TABLE</TT
> is
     added. To use the new method,
     set <A
HREF="runtime-misc.html#GUC-CHECK-TEMP-TABLE"
>check_temp_table</A
>
      to <TT
CLASS="LITERAL"
>trace</TT
>.
    </P
><P
>     Note that it is impossible to trace tables created in
     functions and triggers. In this case existing method should
     be used.
    </P
></LI
><LI
><P
>     Reduce internal queries against system catalogs. (Tatsuo Ishii)
    </P
><P
>     Currently the relcache module issues 7+ queries to obtain
     various info from <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>
     system catalogs. Some of them are necessary for
     <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> to work with multiple
     version of <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>.  To reduce
     such internal queries,
     get <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> version to know
     what kind of queries are needed. For example, we need to
     know if pg_namespace exists and for this purpose we send a
     query against pg_class. But if we know that pg_namespace was
     introduced in <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> 7.3, we
     do not need to inquire pg_class.
    </P
></LI
><LI
><P
>     Performance enhancements for the large INSERT and UPDATE
     statements. (Muhammad Usama)
    </P
><P
>     <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> only needs very little
     information, especially for the INSERT and UPDATE statements
     to decide where it needs to send the query.  For example: In
     master-slave mode, for the INSERT
     statements <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> only
     requires the relation name referenced in the statement while
     it doesn't care much about the column values and other
     parameters. But since the parser we use
     in <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> is taken
     from <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> source which
     parses the complete query including the value lists which
     seems harmless for smaller statements but in case of INSERT
     and UPDATE with lots of column values and large data in
     value items, consumes significant time.
    </P
><P
>     So the idea here is to short circuit the INSERT and UPDATE
     statement parsing as soon as we have the required
     information. For that purpose, the commit adds the second
     minimal parser that gets invoked in master-slave mode and
     tries to extract the performance for large INSERT and UPDATE
     statements.
    </P
><P
>     Apart from the second parser addition, changes aiming
     towards the performance enhancements are also part of the
     commit. See
     the <A
HREF="https://git.postgresql.org/gitweb/?p=pgpool2.git;a=commit;h=310c5c4a289cbe6cee01abef7d2e7bc3550944fb"
TARGET="_top"
>commit
      log</A
> for more details.
    </P
></LI
><LI
><P
>     Import PostgreSQL 12 beta2 new parser. (Bo Peng)
    </P
><P
>     Major changes of PostgreSQL 12 parser include:

     <P
></P
></P><UL
><LI
><P
>	Add new VACUUM options:SKIP_LOCKED, INDEX_CLEANUP and TRUNCATE.
       </P
></LI
><LI
><P
>	Add COMMIT AND CHAIN and ROLLBACK AND CHAIN commands.
       </P
></LI
><LI
><P
>	Add a WHERE clause to COPY FROM.
       </P
></LI
><LI
><P
>	Allow to use CREATE OR REPLACE AGGREGATE command.
       </P
></LI
><LI
><P
>	Allow to use mcv (most-common-value) in CREATE STATISTICS.
       </P
></LI
><LI
><P
>	ADD REINDEX option CONCURRENTLY.
       </P
></LI
><LI
><P
>	Add EXPLAIN option SETTINGS.
       </P
></LI
></UL
><P>
    </P
></LI
><LI
><P
>     Allow to route relcache queries to load balance node. (Tatsuo Ishii)
    </P
><P
>     Queries to build relcache entries were always sent to master (primary)
     node. This is usually good because we could eliminate the bad effect
     of replication delay. However if users want to lower the load of
     master node, it would be nice if we could route the queries to other
     than master node. This patch introduces new parameter
     <A
HREF="runtime-misc.html#GUC-RELCACHE-QUERY-TARGET"
>relcache_query_target</A
>. If it is set to
      <TT
CLASS="LITERAL"
>load_balance_node</TT
>, relcache queries will
      be routed to load balance node.  If it is set
      to <TT
CLASS="LITERAL"
>master</TT
>, the queries are routed to
      master node, which is same as before (this is the default).
    </P
></LI
><LI
><P
>     Disable load balance after a SELECT having functions
     specified in black function list or not specified in white
     function list. (Bo Peng)
    </P
><P
>     In <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 4.0 or earlier, if
     we set <A
HREF="runtime-config-load-balancing.html#GUC-DISABLE-LOAD-BALANCE-ON-WRITE"
>disable_load_balance_on_write</A
> =
      <TT
CLASS="LITERAL"
>transaction</TT
>, when a write query is issued
      inside an explicit truncation, subsequent queries should be
      sent to primary only until the end of this transaction in
      order to avoid the replication delay.  However, the SELECTs
      having write functions specified
      in <A
HREF="runtime-config-load-balancing.html#GUC-BLACK-FUNCTION-LIST"
>black_function_list</A
> or not specified
       in <A
HREF="runtime-config-load-balancing.html#GUC-WHITE-FUNCTION-LIST"
>white_function_list</A
> are not regarded
	as a write query and the subsequent read queries are still
	load balanced. This commit will disable load balance after
	a SELECT having functions specified in black function list
	or not specified in white function list.
    </P
></LI
><LI
><P
>     Implement new feature to not accept incoming
     connections. (Tatsuo Ishii)
    </P
><P
>     <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> accepts up to
     <A
HREF="runtime-config-connection.html#GUC-NUM-INIT-CHILDREN"
>num_init_children</A
> frontends and queues
      up more connection requests until one of child process
      becomes free. This mostly works well, but if each session
      takes long time, the queue grows longer and the whole system
      does not work smoothly.  To overcome the problem, a new way
      to deal with many connection requests from frontend is
      implemented: When <A
HREF="runtime-config-connection.html#GUC-RESERVED-CONNECTIONS"
>reserved_connections</A
>
       is set to 1 or greater, incoming connections from clients
       are not accepted with error message "Sorry, too many clients
       already", rather than blocked if the number of current
       connections from clients is more than
       (<TT
CLASS="VARNAME"
>num_init_children</TT
> -
       <TT
CLASS="VARNAME"
>reserved_connections</TT
>). This is exactly
       the same behavior as <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>.
    </P
></LI
><LI
><P
>     Enhance performance by eliminating select(2) system calls
     when they are not necessary. (Tatsuo Ishii, Jesper Pedersen)
    </P
></LI
><LI
><P
>     Enhance performance while sending message to
     frontend. (Tatsuo Ishii)
    </P
><P
>     SimpleForwardToFrontend(), which is responsible for sending
     message to frontend, does write buffering only if it is
     either 'D' (DataRow) or 'd' (CopyData). Other message types
     were immediately written to socket. But actually this was
     not necessary. So if the messages are not critical, just
     write to buffer.  With this 10-17% performance enhance was
     observed.
    </P
></LI
><LI
><P
>     Avoid error or notice message analysis if it's not
     necessary. (Tatsuo Ishii)
    </P
><P
>     After sending query to
     backend, <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> always calls
     pool_extract_error_message() via per_node_error_log(). In
     the function memory allocation is performed even if error or
     notice message is returned from backend. To avoid the waste
     of CPU cycle, check message kind and avoid calling
     pool_extract_error_message() if it's not error or notice
     message.
    </P
></LI
><LI
><P
>     Enhance performance of CopyData message handling. (Tatsuo Ishii)
    </P
><P
>     When COPY XX FROM STDIN gets executed (typical client is
     pg_dump), each copy row data is sent
     from <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> to frontend using
     CopyData message. Previously, one CopyData message was
     followed by a flush, which costed a lot. Instead, now flush
     is done in subsequent Command Complete, Notice message or
     Error message.  A quick test reveals that this change brings
     x2.5 speed up.
    </P
></LI
><LI
><P
>     Allow to use MD5 hashed password
     in <A
HREF="runtime-config-health-check.html#GUC-HEALTH-CHECK-PASSWORD"
>health_check_password</A
> and
      sr_<A
HREF="runtime-streaming-replication-check.html#GUC-SR-CHECK-PASSWORD"
>sr_check_password</A
>. (Tatsuo Ishii)
    </P
></LI
><LI
><P
>     Support ECDH key exchange with SSL (Takuma Hoshiai)
    </P
></LI
><LI
><P
>     Add backend_application_name to "pgpool show backend" group. (Tatsuo Ishii)
    </P
><P
>&#13;    </P
></LI
><LI
><P
>     Deal with PostgreSQL 12. (Tatsuo Ishii)
    </P
><P
>     recovery.conf cannot be used anymore. Standby's recovery configuration
     is now in postgresql.conf. Also "standby.signal" file is needed in
     PostgreSQL database cluster directory to start postmaster as a standby
     server.
    </P
><P
>     HeapTupleGetOid() is not available any more in PostgreSQL 12. Use
     GETSTRUCT() and refer to oid column of Form_pg_proc.
    </P
><P
>     Change pgpool_adm extension. Now that <TT
CLASS="LITERAL"
>oid</TT
>
     is gone, the signature of CreateTemplateTupleDesc() has been
     changed.
    </P
></LI
><LI
><P
>     Speed up failover when all of backends are down. (Tatsuo
     Ishii)
    </P
><P
>     <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> tries to find primary
     node till <A
HREF="runtime-config-failover.html#GUC-SEARCH-PRIMARY-NODE-TIMEOUT"
>search_primary_node_timeout</A
>
      expires even if all of the backend are in down status. This
      is not only a waste of time but
      makes <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> looked like
      hanged because while searching primary node failover process
      is suspended and all of
      the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> child process are
      in defunct state, thus there's no process which accepts
      connection requests from clients. Since the default value of
      searching primary is 300 seconds, typically this keeps on
      for 300 seconds. This is not comfortable for users.
    </P
><P
>     To fix this immediately give up finding primary node
     regardless
     <A
HREF="runtime-config-failover.html#GUC-SEARCH-PRIMARY-NODE-TIMEOUT"
>search_primary_node_timeout</A
> and
      promptly finish the failover process if all of the backend
      are in down status.
    </P
></LI
><LI
><P
>     Resign the master watchdog node from master responsibilities if
     the primary backend node gets into quarantine state on that. (Muhammad Usama)
    </P
><P
>     By doing this, we could avoid the situation on which there's no
     primary <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> server exists.  To
     implement this, make the master/coordinator watchdog node resign
     from its status if it fails to get the consensus for the
     quarantined primary node failover, within
     FAILOVER_COMMAND_FINISH_TIMEOUT(15) seconds.
    </P
><P
>     When the watchdog master resigns, because of quarantined primary
     node its wd_priority is decreased to (-1), so that it should get
     the least preference in the next election for the
     master/coordinator node selection. And once the election is
     concluded the wd_priority for the node gets restored to the
     original configured value.
    </P
><P
>     In case of failed consensus for standby node failover no action
     is taken.
    </P
></LI
><LI
><P
>     Add parameter <A
HREF="runtime-watchdog-config.html#GUC-ENABLE-CONSENSUS-WITH-HALF-VOTES"
>enable_consensus_with_half_votes</A
> to configure
     majority rule calculations. (Muhammad Usama, Tatsuo Ishii)
    </P
><P
>     <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> takes the decision of quorum
     existence and failover consensus after receiving the exact 50% of
     votes when the watchdog cluster is configured with an even number
     of nodes. With <A
HREF="runtime-watchdog-config.html#GUC-ENABLE-CONSENSUS-WITH-HALF-VOTES"
>enable_consensus_with_half_votes</A
> parameter, users
     can tell <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>, whether the
     distributed consensus in an even number of nodes cluster requires
     (n/2) or ((n/2) +1) votes to decide the majority.  Odd number of
     clusters (3, 5, 7...) are not affected. Extra caution is needed
     for 2 node watchdog cluster users. See <A
HREF="release-4-1-0.html#MIGRATION-TO-VERSION-4-1"
>Section A.3.2</A
> for more details.
    </P
></LI
><LI
><P
>     Allow to specify absolute path in <A
HREF="runtime-config-connection.html#GUC-POOL-PASSWD"
>pool_passwd</A
>. (Bo Peng)
    </P
><P
>     Patch is provided by Danylo Hlynskyi.
    </P
></LI
><LI
><P
>     Add various sample scripts. (Bo Peng)
    </P
><P
>     Allow failover.sh.sample, follow_master.sh.sample, recovery_1st_stage.sample, recovery_2nd_stage.sample,
     pgpool_remote_start.sample scripts to be included in distributions.
    </P
></LI
><LI
><P
>     Documentation enhancements:

     <P
></P
></P><UL
><LI
><P
>	Add performance chapter (<A
HREF="performance.html"
>Chapter 7</A
>). (Tatsuo Ishii)
       </P
></LI
><LI
><P
>	Enhance 'getting started' of 'tutorial' chapter,
	'watchdog' of 'tutorial' and some sections of 'server
	administration'(takuma hoshiai)
       </P
></LI
><LI
><P
>	Update configuration example "Pgpool-II + watchdog
	setup example". (bo peng)
       </P
></LI
><LI
><P
>	Mention that schema qualifications cannot be used in
	white/black_function_list. (tatsuo Ishii)
       </P
></LI
><LI
><P
>	Enhance explanation
	about <A
HREF="runtime-config-failover.html#GUC-FAILOVER-COMMAND"
>failover_command</A
>
	 and <A
HREF="runtime-config-failover.html#GUC-FOLLOW-MASTER-COMMAND"
>follow_master_command</A
>. (tatsuo
	  ishii)
       </P
></LI
><LI
><P
>	Add note to detach_false_primary configuration
	parameter. (tatsuo ishii)
       </P
></LI
><LI
><P
>	Add more explanation to follow_master_command. (tatsuo
	ishii)
       </P
></LI
><LI
><P
>	Enhance watchdog/pgpool-ii example so that it mentions
	about pg_monitor role. (tatsuo ishii)
       </P
></LI
><LI
><P
>	Mention that multi-statement queries are sent to
	primary node only. (tatsuo ishii)
       </P
></LI
><LI
><P
>	Add load balancing description. (tatsuo ishii)
       </P
></LI
><LI
><P
>	Add useful link how to create pcp.conf in the pcp
	reference page. (tatsuo ishii)
       </P
></LI
><LI
><P
>	Add more description to pcp_node_info manual. (tatsuo
	ishii)
       </P
></LI
><LI
><P
>	Add description to pg_md5 man page how to show
	pool_passwd ready string. (tatsuo ishii)
       </P
></LI
><LI
><P
>	Enhance client authentication docs. (tatsuo ishii)
       </P
></LI
><LI
><P
>	Enhance watchdog documents regarding quorum
	failover. (tatsuo ishii)
       </P
></LI
><LI
><P
>	Mention that in raw mode or load_balance_mode = off
	case for relation cache. (tatsuo ishii)
       </P
></LI
><LI
><P
>	Add general description about failover. (tatsuo ishii)
       </P
></LI
></UL
><P>
    </P
></LI
></UL
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="AEN10140"
>A.3.4. Bug fixes</A
></H2
><P
></P
><UL
><LI
><P
>     In this release same bug fixes as <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 4.0.7 are
     already applied. See <A
HREF="release-4-0-7.html"
>Section A.6</A
> for more details of those fixes.
    </P
></LI
></UL
></DIV
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="release-4-1-1.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.html"
ACCESSKEY="H"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="release-4-0-9.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Release 4.1.1</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="release.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>Release 4.0.9</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>