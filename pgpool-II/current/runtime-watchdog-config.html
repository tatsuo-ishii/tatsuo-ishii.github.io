<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Watchdog</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"><LINK
REV="MADE"
HREF="mailto:pgsql-docs@postgresql.org"><LINK
REL="HOME"
TITLE="pgpool-II 4.3devel Documentation"
HREF="index.html"><LINK
REL="UP"
TITLE="Server Configuration"
HREF="runtime-config.html"><LINK
REL="PREVIOUS"
TITLE="Secure Socket Layer (SSL)"
HREF="runtime-ssl.html"><LINK
REL="NEXT"
TITLE="Misc Configuration Parameters"
HREF="runtime-misc.html"><LINK
REL="STYLESHEET"
TYPE="text/css"
HREF="stylesheet.css"><META
HTTP-EQUIV="Content-Type"
CONTENT="text/html; charset=ISO-8859-1"><META
NAME="creation"
CONTENT="2021-05-20T10:15:35"></HEAD
><BODY
CLASS="SECT1"
><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="4"
ALIGN="center"
VALIGN="bottom"
><A
HREF="index.html"
>pgpool-II 4.3devel Documentation</A
></TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
TITLE="Secure Socket Layer (SSL)"
HREF="runtime-ssl.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
HREF="runtime-config.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="60%"
ALIGN="center"
VALIGN="bottom"
>Chapter 5. Server Configuration</TD
><TD
WIDTH="20%"
ALIGN="right"
VALIGN="top"
><A
TITLE="Misc Configuration Parameters"
HREF="runtime-misc.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="RUNTIME-WATCHDOG-CONFIG"
>5.14. Watchdog</A
></H1
><P
>  Watchdog configuration parameters are described in pgpool.conf.
  There is sample configuration in the WATCHDOG section of
  <TT
CLASS="FILENAME"
>pgpool.conf.sample</TT
> file.
  All following options are required to be specified in watchdog process.
 </P
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="CONFIG-ENABLE-WATCHDOG"
>5.14.1. Enable watchdog</A
></H2
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><A
NAME="GUC-USE-WATCHDOG"
></A
><TT
CLASS="VARNAME"
>use_watchdog</TT
> (<TT
CLASS="TYPE"
>boolean</TT
>)
     </DT
><DD
><P
>      If on, activates the watchdog. Default is off
     </P
><P
>      This parameter can only be set at server start.
     </P
><P
>      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 4.1 or earlier, because it is required to specify
      its own pgpool node information and the destination pgpool nodes information, the
      settings are different per pgpool node.
      Since <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 4.2, all configuration parameters are
      identical on all hosts. If watchdog feature is enabled, to distinguish which host
      is which, a <TT
CLASS="FILENAME"
>pgpool_node_id</TT
> file is required.
      You need to create a <TT
CLASS="FILENAME"
>pgpool_node_id</TT
> file and specify the
      pgpool (watchdog) node number (e.g. 0, 1, 2 ...) to identify pgpool (watchdog) host.
     </P
><DIV
CLASS="EXAMPLE"
><A
NAME="EXAMPLE-PGPOOL-NODE-ID-1"
></A
><P
><B
>Example 5-9. pgpool_node_id configuration</B
></P
><P
>       If you have 3 pgpool nodes with hostname server1, server2 and server3, create the
       <TT
CLASS="FILENAME"
>pgpool_node_id</TT
> file on each host as follows.
       When installing <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> using RPM,
       <TT
CLASS="FILENAME"
>pgpool.conf</TT
> is installed under <TT
CLASS="FILENAME"
>/etc/pgpool-II/</TT
>.
      </P
><P
></P
><UL
><LI
><P
>         <TT
CLASS="LITERAL"
>server1</TT
>
        </P
><PRE
CLASS="PROGRAMLISTING"
>[server1]# cat /etc/pgpool-II/pgpool_node_id
0
        </PRE
></LI
><LI
><P
>         <TT
CLASS="LITERAL"
>server2</TT
>
        </P
><PRE
CLASS="PROGRAMLISTING"
>[server2]# cat /etc/pgpool-II/pgpool_node_id
1
        </PRE
></LI
><LI
><P
>         <TT
CLASS="LITERAL"
>server3</TT
>
        </P
><PRE
CLASS="PROGRAMLISTING"
>[server3]# cat /etc/pgpool-II/pgpool_node_id
2
        </PRE
></LI
></UL
></DIV
></DD
></DL
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="CONFIG-COMMUNICATION-WATCHDOG"
>5.14.2. Watchdog communication</A
></H2
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><A
NAME="GUC-HOSTNAME"
></A
><TT
CLASS="VARNAME"
>hostnameX</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the hostname or IP address of
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> server.
      This is used for sending/receiving queries and packets,
      and also as an identifier of the watchdog node.
      The number at the end of the parameter name is referred
      as "pgpool node id", and it starts from 0 (e.g. hostname0).
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-PORT"
></A
><TT
CLASS="VARNAME"
>wd_portX</TT
> (<TT
CLASS="TYPE"
>integer</TT
>)
     </DT
><DD
><P
>      Specifies the port number to be used by watchdog
      process to listen for connections. Default is 9000.
      The number at the end of the parameter name is referred
      as "pgpool node id", and it starts from 0 (e.g. wd_port0).
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-PGPOOL-PORT"
></A
><TT
CLASS="VARNAME"
>pgpool_portX</TT
> (<TT
CLASS="TYPE"
>integer</TT
>)
     </DT
><DD
><P
>      Specifies the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> port number.
      Default is 9999.
      The number at the end of the parameter name is referred
      as "pgpool node id", and it starts from 0 (e.g. pgpool_port0).
     </P
><P
>      This parameter can only be set at server start.
     </P
><DIV
CLASS="EXAMPLE"
><A
NAME="EXAMPLE-WATCHDOG-1"
></A
><P
><B
>Example 5-10. Watchdog configuration</B
></P
><P
>       If you have 3 pgpool nodes with hostname server1, server2 and server3,
       you can configure <A
HREF="runtime-watchdog-config.html#GUC-HOSTNAME"
>hostname</A
>,
       <A
HREF="runtime-watchdog-config.html#GUC-WD-PORT"
>wd_port</A
> and <A
HREF="runtime-watchdog-config.html#GUC-PGPOOL-PORT"
>pgpool_port</A
> like below:
    </P><PRE
CLASS="PROGRAMLISTING"
>hostname0 = 'server1'
wd_port0 = 9000
pgpool_port0 = 9999

hostname1 = 'server2'
wd_port1 = 9000
pgpool_port1 = 9999

hostname2 = 'server3'
wd_port2 = 9000
pgpool_port2 = 9999
    </PRE
><P>
      </P
></DIV
></DD
><DT
><A
NAME="GUC-WD-AUTHKEY"
></A
><TT
CLASS="VARNAME"
>wd_authkey</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the authentication key used for all watchdog communications.
      All <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> must have the same key.
      Packets from watchdog having different key will get rejected.
      This authentication is also applied to the heartbeat signals
      when the <TT
CLASS="LITERAL"
>heartbeat</TT
> mode is used as a lifecheck method.
     </P
><P
>      Since in <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
><SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V3.5</I
></SPAN
> or beyond
      <TT
CLASS="VARNAME"
>wd_authkey</TT
> is also used to authenticate
      the watchdog IPC clients,
      all clients communicating with <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      watchdog process needs to provide this wd_authkey value
      for <TT
CLASS="LITERAL"
>"IPCAuthKey"</TT
> key in the JSON data
      of the command.
     </P
><P
>      Default is <TT
CLASS="LITERAL"
>''</TT
> (empty) which means disables
      the watchdog authentication.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
></DL
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="CONFIG-WATCHDOG-UPSTREAM-CONNECTIONS"
>5.14.3. Upstream server connection</A
></H2
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><A
NAME="GUC-TRUSTED-SERVERS"
></A
><TT
CLASS="VARNAME"
>trusted_servers</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the list of trusted servers to check the up stream connections.
      Each server in the list is required to respond to ping.
      Specify a comma separated list of servers such as
      <TT
CLASS="LITERAL"
>"hostA,hostB,hostC"</TT
>.
      If none of the server are reachable, watchdog will regard it as
      failure of the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>.
      Therefore, it is recommended to specify multiple servers.
      Please note that you should not assign PostgreSQL servers to this parameter.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-PING-PATH"
></A
><TT
CLASS="VARNAME"
>ping_path</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the path of a ping command for monitoring
      connection to the upper servers. Set the only path of the directory containing the
      ping utility, such as <TT
CLASS="LITERAL"
>"/bin"</TT
> or such directory.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
></DL
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="CONFIG-WATCHDOG-VIP-CONTROL"
>5.14.4. Virtual IP control</A
></H2
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><A
NAME="GUC-DELEGATE-IP"
></A
><TT
CLASS="VARNAME"
>delegate_IP</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the virtual IP address (VIP) of
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> that is connected from
      client servers (application servers etc.).  When a
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> is switched from standby to
      active, the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> takes over this
      VIP. <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>VIP will not be brought up in case the quorum
      does not exist</I
></SPAN
>. Default is <TT
CLASS="LITERAL"
>''</TT
>(empty): which
      means virtual IP will never be brought up.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-IF-CMD-PATH"
></A
><TT
CLASS="VARNAME"
>if_cmd_path</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the path to the command that <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      will use to switch the virtual IP on the system.
      Set only the path of the directory containing the binary,
      such as <TT
CLASS="LITERAL"
>"/sbin"</TT
> or such directory.
      If <A
HREF="runtime-watchdog-config.html#GUC-IF-UP-CMD"
>if_up_cmd</A
> or <A
HREF="runtime-watchdog-config.html#GUC-IF-DOWN-CMD"
>if_down_cmd</A
> starts with "/",
      this parameter will be ignored.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-IF-UP-CMD"
></A
><TT
CLASS="VARNAME"
>if_up_cmd</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the command to bring up the virtual IP.
      Set the command and parameters such as
      <TT
CLASS="LITERAL"
>"ip addr add $_IP_$/24 dev eth0 label eth0:0"</TT
>.
      Since root privilege is required to execute this command,
      use <TT
CLASS="COMMAND"
>setuid</TT
> on <TT
CLASS="COMMAND"
>ip</TT
> command or
      allow <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> startup user (<TT
CLASS="LITERAL"
>postgres</TT
> user by default)
      to run <TT
CLASS="COMMAND"
>sudo</TT
> command without a password, and specify it such as
      <TT
CLASS="LITERAL"
>"/usr/bin/sudo /sbin/ip addr add $_IP_$/24 dev eth0 label eth0:0"</TT
>.
      <TT
CLASS="LITERAL"
>$_IP_$</TT
> will get replaced by the IP address
      specified in the <A
HREF="runtime-watchdog-config.html#GUC-DELEGATE-IP"
>delegate_IP</A
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-IF-DOWN-CMD"
></A
><TT
CLASS="VARNAME"
>if_down_cmd</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the command to bring down the virtual IP.
      Set the command and parameters such as
      <TT
CLASS="LITERAL"
>"ip addr del $_IP_$/24 dev eth0"</TT
>.
      Since root privilege is required to execute this command,
      use <TT
CLASS="COMMAND"
>setuid</TT
> on <TT
CLASS="COMMAND"
>ip</TT
> command or
      allow <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> startup user (<TT
CLASS="LITERAL"
>postgres</TT
> user by default)
      to run <TT
CLASS="COMMAND"
>sudo</TT
> command without a password, and specify it such as
      <TT
CLASS="LITERAL"
>"/usr/bin/sudo /sbin/ip addr del $_IP_$/24 dev eth0"</TT
>.
      <TT
CLASS="LITERAL"
>$_IP_$</TT
> will get replaced by the IP address
      specified in the <A
HREF="runtime-watchdog-config.html#GUC-DELEGATE-IP"
>delegate_IP</A
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-ARPING-PATH"
></A
><TT
CLASS="VARNAME"
>arping_path</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the path to the command that <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      will use to send the ARP requests after the virtual IP switch.
      Set only the path of the directory containing the binary,
      such as <TT
CLASS="LITERAL"
>"/usr/sbin"</TT
> or such directory.
      If <A
HREF="runtime-watchdog-config.html#GUC-ARPING-CMD"
>arping_cmd</A
> starts with "/",
      this parameter will be ignored.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-ARPING-CMD"
></A
><TT
CLASS="VARNAME"
>arping_cmd</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the command to use for sending the ARP requests
      after the virtual IP switch.
      Set the command and parameters such as
      <TT
CLASS="LITERAL"
>"arping -U $_IP_$ -w 1 -I eth0"</TT
>.
      Since root privilege is required to execute this command,
      use <TT
CLASS="COMMAND"
>setuid</TT
> on <TT
CLASS="COMMAND"
>ip</TT
> command or
      allow <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> startup user (<TT
CLASS="LITERAL"
>postgres</TT
> user by default)
      to run <TT
CLASS="COMMAND"
>sudo</TT
> command without a password, and specify it such as
      <TT
CLASS="LITERAL"
>"/usr/bin/sudo /usr/sbin/arping -U $_IP_$ -w 1 -I eth0"</TT
>.
      <TT
CLASS="LITERAL"
>$_IP_$</TT
> will get replaced by
      the IP address specified in the <TT
CLASS="VARNAME"
>delegate_IP</TT
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
></DL
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="CONFIG-WATCHDOG-ESCALATION-DE-ESCALATION"
>5.14.5. Behaviour on escalation and de-escalation</A
></H2
><P
>   Configuration about behavior when <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
   escalates to active (virtual IP holder)
  </P
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><A
NAME="GUC-CLEAR-MEMQCACHE-ON-ESCALATION"
></A
><TT
CLASS="VARNAME"
>clear_memqcache_on_escalation</TT
> (<TT
CLASS="TYPE"
>boolean</TT
>)
     </DT
><DD
><P
>      When set to on, watchdog clears all the query cache in the shared memory
      when pgpool-II escalates to active. This prevents the new active <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      from using old query caches inconsistent to the old active.
     </P
><P
>      Default is on.
     </P
><P
>      This works only if <A
HREF="runtime-in-memory-query-cache.html#GUC-MEMQCACHE-METHOD"
>memqcache_method</A
>
       is <TT
CLASS="LITERAL"
>'shmem'</TT
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-ESCALATION-COMMAND"
></A
><TT
CLASS="VARNAME"
>wd_escalation_command</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Watchdog executes this command on the node that is escalated
      to the leader watchdog.
     </P
><P
>      This command is executed just before bringing up the
      virtual IP if that is configured on the node.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-DE-ESCALATION-COMMAND"
></A
><TT
CLASS="VARNAME"
>wd_de_escalation_command</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Watchdog executes this command on the leader <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      watchdog node when that node resigns from the leader node responsibilities.
      A leader watchdog node can resign from being a leader node,
      when the leader node <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> shuts down, detects a network
      blackout or detects the lost of <I
CLASS="FIRSTTERM"
>quorum</I
>.
     </P
><P
>      This command is executed before bringing down the virtual/floating IP address
      if it is configured on the watchdog node.
     </P
><P
>      <TT
CLASS="VARNAME"
>wd_de_escalation_command</TT
> is not available prior to
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II </SPAN
><SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V3.5</I
></SPAN
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
></DL
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="CONFIG-WATCHDOG-FAILOVER-BEHAVIOR"
>5.14.6. Controlling the Failover behavior</A
></H2
><P
>   These settings are used to control the behavior of backend node failover when the watchdog is enabled.
   The effect of these configurations is limited to the failover/degenerate requests initiated by
   <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> internally, while the user initiated detach backend requests
   (using PCP command) by-pass these configuration settings.
  </P
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><A
NAME="GUC-FAILOVER-WHEN-QUORUM-EXISTS"
></A
><TT
CLASS="VARNAME"
>failover_when_quorum_exists</TT
> (<TT
CLASS="TYPE"
>boolean</TT
>)
     </DT
><DD
><P
>      When enabled, <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> will consider quorum when it performs the degenerate/failover on backend node.
     </P
><P
>      We can say that "quorum exists" if the number of live
      watchdog nodes (that is number
      of <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> nodes) can be a
      majority against the total number of watchdog nodes. For
      example, suppose number of watchdog nodes is 5. If number of
      live nodes is greater than or equal to 3, then quorum
      exists. On the other hand if number of live nodes is 2 or
      lower, quorum does not exist since it never be
      majority.
     </P
><P
>      If the quorum exists, <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      could work better on failure detection because even if a
      watchdog node mistakenly detects a failure of backend node,
      it would be denied by other major watchdog nodes.
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> works that way
      when <A
HREF="runtime-watchdog-config.html#GUC-FAILOVER-REQUIRE-CONSENSUS"
>failover_require_consensus</A
> is on
       (the default), but you can change it so that immediate
       failover happens when a failure is detected.
       A <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> node which mistakenly
       detects failure of backend node will quarantine the backend
       node.
     </P
><P
>      The existence of quorum can be shown by invoking <A
HREF="pcp-watchdog-info.html"
>pcp_watchdog_info</A
> command with <TT
CLASS="LITERAL"
>--verbose</TT
> option.
       If <TT
CLASS="LITERAL"
>Quorum state</TT
> is <TT
CLASS="LITERAL"
>QUORUM EXIST</TT
> or <TT
CLASS="LITERAL"
>QUORUM IS ON THE EDGE</TT
>, then the quorum exists.
       If <TT
CLASS="LITERAL"
>Quorum state</TT
> is <TT
CLASS="LITERAL"
>QUORUM ABSENT</TT
>, then the quorum does not exist.
     </P
><P
>      In the absence of the
      quorum, <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> node that
      detects the backend failure will quarantine the failed
      backend node until the quorum exists again.
     </P
><P
>      Although it is possible to force detaching the quarantine
      node by using <TT
CLASS="COMMAND"
>pcp_detach_node</TT
> command, it
      is not possible to attach the node again by
      using <TT
CLASS="COMMAND"
>pcp_attach_node</TT
> command.
     </P
><P
>      The 
      quarantine nodes behaves similar to the detached backend nodes
      but unlike failed/degenerated backends the quarantine status is
      not propagated to the other <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      nodes in the watchdog cluster, So even if the backend node is in
      the quarantine state on one <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      node, other <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> nodes may still
      continue to use that backend.
     </P
><P
>      Although there are many similarities in quarantine and failover operations, but they both differ in a very
      fundamental way. The quarantine operations does not executes the <A
HREF="runtime-config-failover.html#GUC-FAILOVER-COMMAND"
>failover_command</A
>
       and silently detaches the problematic node, So in the case when the main backend node is quarantined, the
       <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> will not promote the standby to take over the main node responsibilities
       and until the main node is quarantined the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> will not have
       any usable main backend node.
     </P
><P
>      Moreover, unlike for the failed nodes,
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> keeps the health-check
      running on the quarantined nodes and as soon as the quarantined
      node becomes reachable again it gets automatically
      re-attached. Note that this is only applied to
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II </SPAN
><SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V4.1</I
></SPAN
>
      or greater. If you are using previous versions you need to
      re-attach the quarantined node by using <A
HREF="pcp-attach-node.html"
>pcp_attach_node</A
> when the connectivity issue is
      solved.
     </P
><P
>      From <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II </SPAN
><SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V4.1</I
></SPAN
> onward, if the watchdog-leader node
      fails to build the consensus for primary backend node failover and the primary backend node gets into a
      quarantine state, then it resigns from its leader/coordinator responsibilities and lowers its wd_priority
      for next leader election and let the cluster elect some different new leader.
      </P><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	When the leader node fails to build the consensus for standby backend node failure, it takes no action
	and similarly quarantined standby backend nodes on watchdog-leader do not trigger a new leader election.
       </P
></BLOCKQUOTE
></DIV
><P>
     </P
><P
>      If this parameter is off, failover will be triggered even if
      quorum does not exist.
     </P
><P
>      Default is on.
     </P
><P
>      <TT
CLASS="VARNAME"
>failover_when_quorum_exists</TT
> is not available prior to
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II </SPAN
><SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V3.7</I
></SPAN
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>       enabling <TT
CLASS="VARNAME"
>failover_when_quorum_exists</TT
> is not allowed in native replication mode.
      </P
></BLOCKQUOTE
></DIV
></DD
><DT
><A
NAME="GUC-FAILOVER-REQUIRE-CONSENSUS"
></A
><TT
CLASS="VARNAME"
>failover_require_consensus</TT
> (<TT
CLASS="TYPE"
>boolean</TT
>)
     </DT
><DD
><P
>      When enabled, <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> will perform the degenerate/failover on a
      backend node if the watchdog quorum exists and at-least minimum number of nodes necessary
      for the quorum vote for the failover.
     </P
><P
>      For example, in a three node watchdog cluster, the failover will only be performed until at
      least two nodes ask for performing the failover on the particular backend node.
     </P
><P
>      If this parameter is off, failover will be triggered even if
      there's no consensus.
     </P
><P
>      Default is on.
     </P
><DIV
CLASS="CAUTION"
><P
></P
><TABLE
CLASS="CAUTION"
BORDER="1"
WIDTH="90%"
><TR
><TD
ALIGN="CENTER"
><B
>Caution</B
></TD
></TR
><TR
><TD
ALIGN="LEFT"
><P
>       When <TT
CLASS="VARNAME"
>failover_require_consensus</TT
> is
       enabled, <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> does not
       execute the failover until it get enough votes from
       other <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> nodes. So it is
       strongly recommended to enable the backend health check on
       all
       <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> nodes to ensure
       proper detection of backend node failures.  For more
       details of health check,
       see <A
HREF="runtime-config-health-check.html"
>Section 5.8</A
>.
      </P
></TD
></TR
></TABLE
></DIV
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>       enabling <TT
CLASS="VARNAME"
>failover_require_consensus</TT
> is not allowed in native replication mode.
      </P
></BLOCKQUOTE
></DIV
><P
>      <TT
CLASS="VARNAME"
>failover_require_consensus</TT
> is not available prior to
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II </SPAN
><SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V3.7</I
></SPAN
>. and it is only
      effective when <A
HREF="runtime-watchdog-config.html#GUC-FAILOVER-WHEN-QUORUM-EXISTS"
>failover_when_quorum_exists</A
> is enabled
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-ALLOW-MULTIPLE-FAILOVER-REQUESTS-FROM-NODE"
></A
><TT
CLASS="VARNAME"
>allow_multiple_failover_requests_from_node</TT
> (<TT
CLASS="TYPE"
>boolean</TT
>)
     </DT
><DD
><P
>      This parameter works in connection with the
      <A
HREF="runtime-watchdog-config.html#GUC-FAILOVER-REQUIRE-CONSENSUS"
>failover_require_consensus</A
>. When enabled, a single <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
       node can cast multiple votes for the failover.
     </P
><P
>      For example, in a three node watchdog cluster, if one <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> node sends two
      failover requests for a particular backend node failover, Both requests will be counted as a separate
      vote in the favor of the failover and <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> will execute the failover,
      even if it does not get the vote from any other <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> node.
     </P
><P
>      For example, if an error found in a health check round does
      not get enough vote and the error still persists, next round
      of health check will give one more vote.  This parameter is
      useful if you want to detect a persistent error which might
      not be found by other watchdog nodes.
     </P
><P
>      Default is off.
     </P
><P
>      <TT
CLASS="VARNAME"
>allow_multiple_failover_requests_from_node</TT
> is not available prior to
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II </SPAN
><SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V3.7</I
></SPAN
>. and it is only
      effective when both <A
HREF="runtime-watchdog-config.html#GUC-FAILOVER-WHEN-QUORUM-EXISTS"
>failover_when_quorum_exists</A
> and
       <A
HREF="runtime-watchdog-config.html#GUC-FAILOVER-REQUIRE-CONSENSUS"
>failover_require_consensus</A
> are enabled
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-ENABLE-CONSENSUS-WITH-HALF-VOTES"
></A
><TT
CLASS="VARNAME"
>enable_consensus_with_half_votes</TT
> (<TT
CLASS="TYPE"
>boolean</TT
>)
     </DT
><DD
><P
>      This parameter configures how the majority rule computation
      is made by <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> for calculating
      the quorum and resolving the consensus for failover.
     </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>       This parameter affects not only the failover behavior of the
       backend but the quorum and the failover behavior of
       <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> itself.
      </P
></BLOCKQUOTE
></DIV
><P
>      When enabled the existence of quorum and consensus on failover requires only half of
      the total number of votes configured in the cluster. Otherwise, both of these
      decisions require at least one more vote than half of the total number of votes.
      For failover, this parameter works in conjunction with the
      <A
HREF="runtime-watchdog-config.html#GUC-FAILOVER-REQUIRE-CONSENSUS"
>failover_require_consensus</A
>. In both cases, whether making a
      decision of quorum existence or building the consensus on failover this
      parameter only comes into play when the watchdog cluster is configured for even
      number of <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> nodes.
      The majority rule decision in the watchdog cluster having an odd number of participants.
      It is not affected by the value of this configuration parameter.
     </P
><P
>      For example, when this parameter is enabled in a two node watchdog
      cluster, one <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> node needs to
      be alive to make the quorum exist. If the parameter is off, two
      nodes need to be alive to make quorum exist.
     </P
><P
>      When this parameter is enabled in a four node watchdog cluster,
      two <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> node needs to be alive
      to make the quorum exist. If the parameter is off, three nodes
      need to be alive to make quorum exist.
     </P
><P
>      By enabling this parameter, you should aware that you take a
      risk to make split-brain happen. For example, in four node
      cluster consisted of node A, B, C and D, it is possible that the
      cluster goes into two separated networks (A, B) and (C, D). For
      (A, B) and (C, D) the quorum still exist since for both groups
      there are two live nodes out of 4. The two groups choose their
      own leader watchdog, which is a split-brain.
     </P
><P
>      Default is off.
     </P
><P
>      <TT
CLASS="VARNAME"
>enable_consensus_with_half_votes</TT
> is not available
      prior to <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II
      </SPAN
><SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V4.1</I
></SPAN
>. The prior versions work
      as if the parameter is on.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
></DL
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="CONFIG-WATCHDOG-LIFECHECK"
>5.14.7. Life checking <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
></A
></H2
><P
>   Watchdog checks pgpool-II status periodically. This is called "life check".
  </P
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><A
NAME="GUC-WD-LIFECHECK-METHOD"
></A
><TT
CLASS="VARNAME"
>wd_lifecheck_method</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the method of life check. This can be either of <TT
CLASS="LITERAL"
>'heartbeat'</TT
> (default),
      <TT
CLASS="LITERAL"
>'query'</TT
> or <TT
CLASS="LITERAL"
>'external'</TT
>.
     </P
><P
>      <TT
CLASS="LITERAL"
>heartbeat</TT
>: In this mode, watchdog sends the heartbeat signals (<ACRONYM
CLASS="ACRONYM"
>UDP</ACRONYM
> packets)
      periodically to other <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>. Similarly watchdog also receives the signals
      from other <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> .
      If there are no signal for a certain period, watchdog regards is as failure
      of the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> .
     </P
><P
>      <TT
CLASS="LITERAL"
>query</TT
>: In this mode, watchdog sends the monitoring queries
      to other <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> and checks the response.
      When installation location between <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      servers is far, <TT
CLASS="LITERAL"
>query</TT
> may be useful.
      <DIV
CLASS="CAUTION"
><P
></P
><TABLE
CLASS="CAUTION"
BORDER="1"
WIDTH="90%"
><TR
><TD
ALIGN="CENTER"
><B
>Caution</B
></TD
></TR
><TR
><TD
ALIGN="LEFT"
><P
>        In query mode, you need to set <A
HREF="runtime-config-connection.html#GUC-NUM-INIT-CHILDREN"
>num_init_children</A
>
	 large enough if you plan to use watchdog.
	 This is because the watchdog process connects to
	 <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> as a client.
       </P
></TD
></TR
></TABLE
></DIV
>
     </P
><P
>      <TT
CLASS="LITERAL"
>external</TT
>: This mode disables the built
      in lifecheck of <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> watchdog
      and relies on external system to provide node health checking
      of local and remote watchdog nodes.
     </P
><P
>      <TT
CLASS="LITERAL"
>external</TT
> mode is not available in versions prior to
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V3.5</I
></SPAN
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-MONITORING-INTERFACES-LIST"
></A
><TT
CLASS="VARNAME"
>wd_monitoring_interfaces_list</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specify a comma separated list of network device names, to be monitored by the watchdog process
      for the network link state. If all network interfaces in the list becomes inactive
      (disabled or cable unplugged), the watchdog will consider it as a complete network failure
      and the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> node will commit the suicide.
      Specifying an <TT
CLASS="LITERAL"
>''</TT
>(empty) list disables the network interface monitoring.
      Setting it to <TT
CLASS="LITERAL"
>'any'</TT
> enables the monitoring on all available network interfaces
      except the loopback. Default is <TT
CLASS="LITERAL"
>''</TT
> empty list (monitoring disabled).
     </P
><P
>      <TT
CLASS="VARNAME"
>wd_monitoring_interfaces_list</TT
> is not available in versions prior to
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V3.5</I
></SPAN
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-INTERVAL"
></A
><TT
CLASS="VARNAME"
>wd_interval</TT
> (<TT
CLASS="TYPE"
>integer</TT
>)
     </DT
><DD
><P
>      Specifies the interval between life checks of <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      in seconds. (A number greater than or equal to 1) Default is 10.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-PRIORITY"
></A
><TT
CLASS="VARNAME"
>wd_priority</TT
> (<TT
CLASS="TYPE"
>integer</TT
>)
     </DT
><DD
><P
>      This parameter can be used to elevate the local watchdog node priority in the elections
      to select leader watchdog node.
      The node with the higher <TT
CLASS="VARNAME"
>wd_priority</TT
> value will get selected
      as leader watchdog node when cluster will be electing its new leader node
      in the event of old leader watchdog node failure.
      <TT
CLASS="VARNAME"
>wd_priority</TT
> is also valid at the time of cluster startup.
      When some watchdog nodes start up at same time,a node with the higher <TT
CLASS="VARNAME"
>wd_priority</TT
>
      value is selected as a leader node.
      So we should start watchdog nodes in order of <TT
CLASS="VARNAME"
>wd_priority</TT
> priority to prevent
      unintended nodes from being selected as leader.
     </P
><P
>      <TT
CLASS="VARNAME"
>wd_priority</TT
> is not available in versions prior to
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V3.5</I
></SPAN
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-IPC-SOCKET-DIR"
></A
><TT
CLASS="VARNAME"
>wd_ipc_socket_dir</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      The directory where the <ACRONYM
CLASS="ACRONYM"
>UNIX</ACRONYM
> domain socket
      accepting <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      watchdog <ACRONYM
CLASS="ACRONYM"
>IPC</ACRONYM
> connections will be created.
      Default is <TT
CLASS="LITERAL"
>'/tmp'</TT
>.
      Be aware that this socket might be deleted by a cron job.
      We recommend to set this value to <TT
CLASS="LITERAL"
>'/var/run'</TT
> or such directory.
     </P
><P
>      <TT
CLASS="VARNAME"
>wd_ipc_socket_dir</TT
> is not available in versions prior to
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>V3.5</I
></SPAN
>.
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
></DL
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="CONFIG-WATCHDOG-LIFECHECK-HEARTBEAT"
>5.14.8. Lifecheck Heartbeat mode configuration</A
></H2
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><A
NAME="GUC-HEARTBEAT-HOSTNAME"
></A
><TT
CLASS="VARNAME"
>heartbeat_hostnameX</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the <ACRONYM
CLASS="ACRONYM"
>IP</ACRONYM
> address or <ACRONYM
CLASS="ACRONYM"
>hostname</ACRONYM
>
	  for sending and receiving the heartbeat signals.
      The number at the end of the parameter name is referred
      as "pgpool node id", and it starts from 0 (e.g. heartbeat_hostname0).
	  You can specify multiple <ACRONYM
CLASS="ACRONYM"
>IP</ACRONYM
> address or <ACRONYM
CLASS="ACRONYM"
>hostname</ACRONYM
>
      by separating them using semicolon (;).
     </P
><P
>      <TT
CLASS="VARNAME"
>heartbeat_hostnameX</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'heartbeat'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-HEARTBEAT-PORT"
></A
><TT
CLASS="VARNAME"
>heartbeat_portX</TT
> (<TT
CLASS="TYPE"
>integer</TT
>)
     </DT
><DD
><P
>      Specifies the port number for sending and receiving the heartbeat signals.
      Specify only one port number here. Default is 9694.
      The number at the end of the parameter name is referred
      as "pgpool node id", and it starts from 0 (e.g. heartbeat_port0).
     </P
><P
>      <TT
CLASS="VARNAME"
>heartbeat_portX</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'heartbeat'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-HEARTBEAT-DEVICE"
></A
><TT
CLASS="VARNAME"
>heartbeat_deviceX</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the network device name for sending and receiving the heartbeat signals.
      The number at the end of the parameter name is referred
      as "pgpool node id", and it starts from 0 (e.g. heartbeat_device0).
	  You can specify multiple network devices by separating them using semicolon (;).
     </P
><P
>      <TT
CLASS="VARNAME"
>heartbeat_deviceX</TT
> is only applicable if
      <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> is started with root
      privilege. If not, leave it as an empty string ('').
     </P
><P
>      <TT
CLASS="VARNAME"
>heartbeat_deviceX</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'heartbeat'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
><DIV
CLASS="EXAMPLE"
><A
NAME="EXAMPLE-HEARTBEAT-1"
></A
><P
><B
>Example 5-11. Heartbeat configuration</B
></P
><P
>       If you have 3 pgpool nodes with hostname server1, server2 and server3,
       you can configure <A
HREF="runtime-watchdog-config.html#GUC-HEARTBEAT-HOSTNAME"
>heartbeat_hostname</A
>,
       <A
HREF="runtime-watchdog-config.html#GUC-HEARTBEAT-PORT"
>heartbeat_port</A
> and <A
HREF="runtime-watchdog-config.html#GUC-HEARTBEAT-DEVICE"
>heartbeat_device</A
> like below:
	</P><PRE
CLASS="PROGRAMLISTING"
>     heartbeat_hostname0 = 'server1'
     heartbeat_port0 = 9694
     heartbeat_device0 = ''

     heartbeat_hostname1 = 'server2'
     heartbeat_port1 = 9694
     heartbeat_device1 = ''

     heartbeat_hostname2 = 'server3'
     heartbeat_port2 = 9694
     heartbeat_device2 = ''
	</PRE
><P>
      </P
></DIV
></DD
><DT
><A
NAME="GUC-WD-HEARTBEAT-KEEPALIVE"
></A
><TT
CLASS="VARNAME"
>wd_heartbeat_keepalive</TT
> (<TT
CLASS="TYPE"
>integer</TT
>)
     </DT
><DD
><P
>      Specifies the interval time in seconds between sending the heartbeat signals.
      Default is 2.
      <TT
CLASS="VARNAME"
>wd_heartbeat_keepalive</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'heartbeat'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-HEARTBEAT-DEADTIME"
></A
><TT
CLASS="VARNAME"
>wd_heartbeat_deadtime</TT
> (<TT
CLASS="TYPE"
>integer</TT
>)
     </DT
><DD
><P
>      Specifies the time in seconds before marking the remote watchdog node as failed/dead node,
      if no heartbeat signal is received within that time.
      Default is <TT
CLASS="LITERAL"
>30</TT
>
      <TT
CLASS="VARNAME"
>wd_heartbeat_deadtime</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'heartbeat'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
></DL
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="CONFIG-WATCHDOG-LIFECHECK-QUERY"
>5.14.9. Lifecheck Query mode configuration</A
></H2
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><A
NAME="GUC-WD-LIFE-POINT"
></A
><TT
CLASS="VARNAME"
>wd_life_point</TT
> (<TT
CLASS="TYPE"
>integer</TT
>)
     </DT
><DD
><P
>      Specifies the number of times to retry a failed life check of pgpool-II.
      Valid value could be a number greater than or equal to 1.
      Default is 3.
     </P
><P
>      <TT
CLASS="VARNAME"
>wd_life_point</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'query'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-LIFECHECK-QUERY"
></A
><TT
CLASS="VARNAME"
>wd_lifecheck_query</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the query to use for the life check of remote <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>.
      Default is <TT
CLASS="LITERAL"
>"SELECT 1"</TT
>.
     </P
><P
>      <TT
CLASS="VARNAME"
>wd_lifecheck_query</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'query'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-LIFECHECK-DBNAME"
></A
><TT
CLASS="VARNAME"
>wd_lifecheck_dbname</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the database name for the connection used for the
      life check of remote <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>.
      Default is <TT
CLASS="LITERAL"
>"template1"</TT
>.
     </P
><P
>      <TT
CLASS="VARNAME"
>wd_lifecheck_dbname</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'query'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-LIFECHECK-USER"
></A
><TT
CLASS="VARNAME"
>wd_lifecheck_user</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the user name for the connection used for the life
      check of remote <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>.
      Default is <TT
CLASS="LITERAL"
>"nobody"</TT
>.
     </P
><P
>      <TT
CLASS="VARNAME"
>wd_lifecheck_user</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'query'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
></DD
><DT
><A
NAME="GUC-WD-LIFECHECK-PASSWORD"
></A
><TT
CLASS="VARNAME"
>wd_lifecheck_password</TT
> (<TT
CLASS="TYPE"
>string</TT
>)
     </DT
><DD
><P
>      Specifies the password for the user used for the life check of remote <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>.
     </P
><P
>      If <TT
CLASS="VARNAME"
>wd_lifecheck_password</TT
> is left blank <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
      will first try to get the password for <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-USER"
>wd_lifecheck_user</A
> from
       <A
HREF="runtime-config-connection.html#GUC-POOL-PASSWD"
>pool_passwd</A
> file before using the empty password.
     </P
><P
>      You can also specify AES256-CBC encrypted password in <TT
CLASS="VARNAME"
>wd_lifecheck_password</TT
> field.
      To specify the <TT
CLASS="LITERAL"
>AES</TT
> encrypted password, password string must be prefixed with
      <TT
CLASS="LITERAL"
>AES</TT
> after encrypting (using <TT
CLASS="LITERAL"
>aes-256-cbc</TT
> algorithm) and
      encoding to <TT
CLASS="LITERAL"
>base64</TT
>.
     </P
><P
>      To specify the unencrypted clear text password, prefix the password string with
      <TT
CLASS="LITERAL"
>TEXT</TT
>. For example if you want to set <TT
CLASS="LITERAL"
>mypass</TT
> as
      a password, you should specify <TT
CLASS="LITERAL"
>TEXTmypass</TT
> in the password field.
      In the absence of a valid prefix, <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> will considered
      the string as a plain text password.
     </P
><P
>      You can also use <A
HREF="pg-enc.html"
>pg_enc</A
> utility to create the correctly formatted
       <TT
CLASS="LITERAL"
>AES</TT
> encrypted password strings.
       </P><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> will require a valid decryption key at the
	 startup to use the encrypted passwords.
	 see <A
HREF="auth-aes-encrypted-password.html#AUTH-AES-DECRYPTION-KEY"
>Section 6.4.2</A
> for more details on providing the
	  decryption key to <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
	</P
></BLOCKQUOTE
></DIV
><P>
     </P
><P
>      <TT
CLASS="VARNAME"
>wd_lifecheck_password</TT
> is only applicable if the
      <A
HREF="runtime-watchdog-config.html#GUC-WD-LIFECHECK-METHOD"
>wd_lifecheck_method</A
> is set to <TT
CLASS="LITERAL"
>'query'</TT
>
     </P
><P
>      This parameter can only be set at server start.
     </P
><P
>      Default is <TT
CLASS="LITERAL"
>''</TT
>(empty).
     </P
></DD
></DL
></DIV
></DIV
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="runtime-ssl.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.html"
ACCESSKEY="H"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="runtime-misc.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Secure Socket Layer (SSL)</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="runtime-config.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>Misc Configuration Parameters</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>