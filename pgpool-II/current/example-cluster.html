<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Pgpool-II + Watchdog Setup Example</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"><LINK
REV="MADE"
HREF="mailto:pgsql-docs@postgresql.org"><LINK
REL="HOME"
TITLE="pgpool-II 4.1devel Documentation"
HREF="index.html"><LINK
REL="UP"
TITLE="Configuration Examples"
HREF="example-configs.html"><LINK
REL="PREVIOUS"
TITLE="Watchdog Configuration Example"
HREF="example-watchdog.html"><LINK
REL="NEXT"
TITLE="AWS Configuration Example"
HREF="example-aws.html"><LINK
REL="STYLESHEET"
TYPE="text/css"
HREF="stylesheet.css"><META
HTTP-EQUIV="Content-Type"
CONTENT="text/html; charset=ISO-8859-1"><META
NAME="creation"
CONTENT="2018-11-23T05:32:46"></HEAD
><BODY
CLASS="SECT1"
><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="4"
ALIGN="center"
VALIGN="bottom"
><A
HREF="index.html"
>pgpool-II 4.1devel Documentation</A
></TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
TITLE="Watchdog Configuration Example"
HREF="example-watchdog.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
HREF="example-configs.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="60%"
ALIGN="center"
VALIGN="bottom"
>Chapter 7. Configuration Examples</TD
><TD
WIDTH="20%"
ALIGN="right"
VALIGN="top"
><A
TITLE="AWS Configuration Example"
HREF="example-aws.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="EXAMPLE-CLUSTER"
>7.3. <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> + Watchdog Setup Example</A
></H1
><P
>This section shows an example of streaming replication configuration using <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>. In this example, we use 3 <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> servers to manage <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> servers to create a robust cluster system and avoid the single point of failure or split brain.
      </P
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-REQUIREMENT"
>7.3.1. Requirements</A
></H2
><P
>We assume that all the Pgpool-II servers and the <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> servers are in the same subnet.
        </P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-STRUCTURE"
>7.3.2. Cluster System Configuration</A
></H2
><P
>We use 2 <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> servers and 3 <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> servers with CentOS7. Let these servers be <TT
CLASS="LITERAL"
>osspc16</TT
>, <TT
CLASS="LITERAL"
>osspc17</TT
>, <TT
CLASS="LITERAL"
>osspc18</TT
>, <TT
CLASS="LITERAL"
>osspc19</TT
> and <TT
CLASS="LITERAL"
>osspc20</TT
>.
        </P
><P
>          <DIV
CLASS="FIGURE"
><A
NAME="AEN5385"
></A
><P
><B
>Figure 7-1. Cluster System Configuration</B
></P
><DIV
CLASS="MEDIAOBJECT"
><P
><IMG
SRC="cluster.gif"></P
></DIV
></DIV
>
        </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>          The roles of <TT
CLASS="LITERAL"
>Active</TT
>, <TT
CLASS="LITERAL"
>Standy</TT
>, <TT
CLASS="LITERAL"
>Primary</TT
>, <TT
CLASS="LITERAL"
>Standby</TT
> are not fixed and may be changed by further operations.
          </P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-INSTALLATION"
>7.3.3. Installation</A
></H2
><P
>In this example, we install <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> and <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> by using RPM packages.
        </P
><DIV
CLASS="TABLE"
><A
NAME="EXAMPLE-CLUSTER-TABLE"
></A
><P
><B
>Table 7-2. <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>, <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> version informations and Configuration</B
></P
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL><COL><COL><COL><COL><THEAD
><TR
><TH
>Server</TH
><TH
>Version</TH
><TH
>Host Name</TH
><TH
>Port</TH
><TH
>$PGDATA Directory</TH
></TR
></THEAD
><TBODY
><TR
><TD
><SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> server (primary)</TD
><TD
><SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> 9.6.1</TD
><TD
>osspc19</TD
><TD
>5432</TD
><TD
>/var/lib/pgsql/9.6/data</TD
></TR
><TR
><TD
><SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> server (standby) </TD
><TD
><SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> 9.6.1</TD
><TD
>osspc20</TD
><TD
>5432</TD
><TD
>/var/lib/pgsql/9.6/data</TD
></TR
><TR
><TD
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> server</TD
><TD
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 3.6.1</TD
><TD
>osspc16</TD
><TD
>9999</TD
><TD
>-</TD
></TR
><TR
><TD
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> server</TD
><TD
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 3.6.1</TD
><TD
>osspc17</TD
><TD
>9999</TD
><TD
>-</TD
></TR
><TR
><TD
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> server</TD
><TD
><SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> 3.6.1</TD
><TD
>osspc18</TD
><TD
>9999</TD
><TD
>-</TD
></TR
></TBODY
></TABLE
></DIV
><P
>        Install <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> by using Pgpool-II YUM repository.
      </P
><PRE
CLASS="PROGRAMLISTING"
># yum install http://www.pgpool.net/yum/rpms/3.6/redhat/rhel-7-x86_64/pgpool-II-release-3.6-1.noarch.rpm
# yum install pgpool-II-pg96
# yum install pgpool-II-pg96-debuginfo
# yum install pgpool-II-pg96-devel
# yum install pgpool-II-pg96-extensions
      </PRE
><P
>        Install <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> by using <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> YUM repository.
      </P
><PRE
CLASS="PROGRAMLISTING"
># yum install https://yum.postgresql.org/9.6/redhat/rhel-7-x86_64/pgdg-centos96-9.6-3.noarch.rpm
# yum install postgresql96 postgresql96-devel postgresql96-server
      </PRE
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-PRE-SETUP"
>7.3.4. Before Starting</A
></H2
><P
>      Before you start the configuration process, please check the following prerequisites.
      </P
><P
></P
><UL
><LI
><P
>Set up <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> streaming replication on the primary server. In this example, we use WAL archiving.
          </P
><P
>First, we create the directory <TT
CLASS="FILENAME"
>/var/lib/pgsql/archivedir</TT
> to store <ACRONYM
CLASS="ACRONYM"
>WAL</ACRONYM
> segments on both <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> servers (<TT
CLASS="LITERAL"
>osspc19</TT
> and <TT
CLASS="LITERAL"
>osspc20</TT
>).
          </P
><PRE
CLASS="PROGRAMLISTING"
>[PostgreSQL server]$ mkdir /var/lib/pgsql/archivedir
          </PRE
><P
>Then we edit the configuration file <TT
CLASS="FILENAME"
>$PGDATA/postgresql.conf</TT
> on <TT
CLASS="LITERAL"
>osspc19</TT
> (primary) as follows.
          </P
><PRE
CLASS="PROGRAMLISTING"
>listen_addresses = '*'
wal_level = hot_standby
max_wal_senders = 2

archive_mode = on
archive_command = 'cp "%p" "/var/lib/pgsql/archivedir/%f"'
          </PRE
><P
>We use the online recovery functionality of Pgpool-II to setup standby server after the primary server is started.
          </P
></LI
><LI
><P
>Because of the security reasons, we create a user <TT
CLASS="LITERAL"
>repl</TT
> solely used for replication purpose, and a user <TT
CLASS="LITERAL"
>pgpool</TT
> for streaming replication delay check and health check of <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>. Assuming that all the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> servers and the <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> servers are in the network of <TT
CLASS="LITERAL"
>133.137.174.0/24</TT
>, and edit <TT
CLASS="FILENAME"
>pg_hba.conf</TT
> to enable <TT
CLASS="LITERAL"
>md5</TT
> authentication method.
          </P
><PRE
CLASS="PROGRAMLISTING"
>host    all             pgpool          133.137.174.0/24         md5
host    all             all             0.0.0.0/0                md5

host    replication     repl            133.137.174.0/24         md5
          </PRE
></LI
><LI
><P
>To use the failover and online recovery of <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>, the settings that allow SSH without passowrd to other servers (<TT
CLASS="LITERAL"
>osspc16</TT
> - <TT
CLASS="LITERAL"
>osspc20</TT
>) are necessary.
          </P
></LI
><LI
><P
>To allow <TT
CLASS="LITERAL"
>repl</TT
> user without specifying password for streaming replication and online recovery, we create the <TT
CLASS="FILENAME"
>.pgpass</TT
> file in <TT
CLASS="LITERAL"
>postgres</TT
> user's home directory and change the permisson  to <TT
CLASS="LITERAL"
>600</TT
> on both postgreSQL servers <TT
CLASS="LITERAL"
>osspc19</TT
> and <TT
CLASS="LITERAL"
>osspc20</TT
>.
          </P
><PRE
CLASS="PROGRAMLISTING"
>[osspc19]$ cat /var/lib/pgsql/.pgpass
osspc20:5432:replication:repl:&lt;password of repl user&gt;
            </PRE
><PRE
CLASS="PROGRAMLISTING"
>[osspc20]$ cat /var/lib/pgsql/.pgpass
osspc19:5432:replication:repl:&lt;passowrd of repl user&gt;
            </PRE
><PRE
CLASS="PROGRAMLISTING"
>$ chmod 600  /var/lib/pgsql/.pgpass
            </PRE
></LI
><LI
><P
>When <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> connects to other <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> servers or <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> servers, the target port must be accessible by enabling firewall management softwares. Following is an example for <SPAN
CLASS="SYSTEMITEM"
>CentOS/RHEL7</SPAN
>.
          </P
><PRE
CLASS="PROGRAMLISTING"
>[PostgreSQL server]# firewall-cmd --permanent --zone=public --add-service=postgresql
[PostgreSQL server]# firewall-cmd --reload
            </PRE
></LI
><LI
><P
>The following commands are to enable <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> and <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> start on system boot.
          </P
><PRE
CLASS="PROGRAMLISTING"
>[Pgpool-II server]# systemctl enable pgpool.service
            </PRE
><PRE
CLASS="PROGRAMLISTING"
>[PostgreSQL server]# systemctl enable postgresql.service
            </PRE
></LI
></UL
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG"
>7.3.5. <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> Configuration</A
></H2
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-COMMON"
>7.3.5.1. Common Settings</A
></H3
><P
>Here are the common settings on <TT
CLASS="LITERAL"
>osspc16</TT
>, <TT
CLASS="LITERAL"
>osspc17</TT
> and <TT
CLASS="LITERAL"
>osspc18</TT
>.
        </P
><P
>When installing Pgpool-II from RPM,  all the Pgpool-II configuration files are in <TT
CLASS="FILENAME"
>/etc/pgpool-II</TT
>. In this example, we copy the sample configuration file for streaming replicaton mode.
        </P
><PRE
CLASS="PROGRAMLISTING"
># cp /etc/pgpool-II/pgpool.conf.sample-stream /etc/pgpool-II/pgpool.conf
        </PRE
><P
>To allow Pgpool-II to accept all incoming connections, we set <TT
CLASS="VARNAME"
>listen_addresses = '*'</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
>listen_addresses = '*'
        </PRE
><P
>Specifiy replication delay check user and password.
        </P
><PRE
CLASS="PROGRAMLISTING"
>sr_check_user = 'pgpool'
sr_check_password = 'pgpool'
        </PRE
><P
>Enable health check so that pgpool-II performs failover. Also, if the network is unstable, the health check fails even though the backend is running properly, failover or degenerate operation may occur. In order to prevent such incorrect detection of health check, we set <TT
CLASS="VARNAME"
>health_check_max_retries = 10</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
>health_check_period = 5
                                   # Health check period
                                   # Disabled (0) by default
health_check_timeout = 20
                                   # Health check timeout
                                   # 0 means no timeout
health_check_user = 'pgpool'
health_check_password = 'pgpool'

health_check_max_retries = 10
        </PRE
><P
>Specify the backend informations with <TT
CLASS="LITERAL"
>osspc19</TT
> and <TT
CLASS="LITERAL"
>osspc20</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
># - Backend Connection Settings -

backend_hostname0 = 'osspc19'
                                   # Host name or IP address to connect to for backend 0
backend_port0 = 5432
                                   # Port number for backend 0
backend_weight0 = 1
                                   # Weight for backend 0 (only in load balancing mode)
backend_data_directory0 = '/var/lib/pgsql/9.6/data'
                                   # Data directory for backend 0
backend_flag0 = 'ALLOW_TO_FAILOVER'
                                   # Controls various backend behavior
                                   # ALLOW_TO_FAILOVER or DISALLOW_TO_FAILOVER
backend_hostname1 = 'osspc20'
backend_port1 = 5432
backend_weight1 = 1
backend_data_directory1 = '/var/lib/pgsql/9.6/data'
backend_flag1 = 'ALLOW_TO_FAILOVER'
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-FAILOVER"
>7.3.5.2. Failover configuration</A
></H3
><P
>Specify <TT
CLASS="VARNAME"
>failover_command</TT
> to execute failover.sh script. The special characters <TT
CLASS="COMMAND"
>%d %P %H %R</TT
> in failover_command are replcaed with <TT
CLASS="LITERAL"
>DB node ID of the detached node</TT
>,  <TT
CLASS="LITERAL"
>Old primary node ID</TT
>, <TT
CLASS="LITERAL"
>Hostname of the new master node</TT
>, <TT
CLASS="LITERAL"
>Database cluster directory of the new master node</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
>failover_command = '/etc/pgpool-II/failover.sh %d %P %H %R'
      </PRE
><P
>Create <TT
CLASS="FILENAME"
>/etc/pgpool-II/failover.sh</TT
>, and set the file permisson to <TT
CLASS="LITERAL"
>755</TT
>.
      </P
><PRE
CLASS="PROGRAMLISTING"
># vi /etc/pgpool-II/failover.sh
# chmod 755 /etc/pgpool-II/failover.sh
      </PRE
><P
></P
><UL
><LI
><P
>/etc/pgpool-II/failover.sh
          </P
><PRE
CLASS="PROGRAMLISTING"
>#! /bin/sh -x
# Execute command by failover.
# special values:  %d = node id
#                  %h = host name
#                  %p = port number
#                  %D = database cluster path
#                  %m = new master node id
#                  %M = old master node id
#                  %H = new master node host name
#                  %P = old primary node id
#                  %R = new master database cluster path
#                  %r = new master port number
#                  %% = '%' character

falling_node=$1          # %d
old_primary=$2           # %P
new_primary=$3           # %H
pgdata=$4                # %R

pghome=/usr/pgsql-9.6
log=/var/log/pgpool/failover.log

date &#62;&#62; $log
echo "failed_node_id=$falling_node new_primary=$new_primary" &#62;&#62; $log

if [ $falling_node = $old_primary ]; then
    if [ $UID -eq 0 ]
    then
        su postgres -c "ssh -T postgres@$new_primary $pghome/bin/pg_ctl promote -D $pgdata"
    else
        ssh -T postgres@$new_primary $pghome/bin/pg_ctl promote -D $pgdata
    fi
    exit 0;
fi;
exit 0;
          </PRE
></LI
></UL
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-ONLINE-RECOVERY"
>7.3.5.3. Pgpool-II Online Recovery Configurations</A
></H3
><P
>Next, in order to perform online recovery with <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> we specify the <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> user name and online recovery command <TT
CLASS="COMMAND"
>recovery_1st_stage</TT
>. Then, we create <TT
CLASS="FILENAME"
>recovery_1st_stage</TT
> and <TT
CLASS="FILENAME"
>pgpool_remote_start</TT
> in database cluster directory of <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> primary server, and set the file permissions to <TT
CLASS="LITERAL"
>755</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
>recovery_user = 'postgres'
                                   # Online recovery user
recovery_password = 'postgres'
                                   # Online recovery password

recovery_1st_stage_command = 'recovery_1st_stage'
        </PRE
><PRE
CLASS="PROGRAMLISTING"
>$ vi /var/lib/pgsql/9.6/data/recovery_1st_stage
$ vi /var/lib/pgsql/9.6/data/pgpool_remote_start
$ chmod 755 /var/lib/pgsql/9.6/data/recovery_1st_stage
$ chmod 755 /var/lib/pgsql/9.6/data/pgpool_remote_start
        </PRE
><P
></P
><UL
><LI
><P
>/var/lib/pgsql/9.6/data/recovery_1st_stage
            </P
><PRE
CLASS="PROGRAMLISTING"
>#!/bin/bash -x
# Recovery script for streaming replication.

pgdata=$1
remote_host=$2
remote_pgdata=$3
port=$4

pghome=/usr/pgsql-9.6
archivedir=/var/lib/pgsql/archivedir
hostname=$(hostname)

ssh -T postgres@$remote_host "
rm -rf $remote_pgdata
$pghome/bin/pg_basebackup -h $hostname -U repl -D $remote_pgdata -x -c fast
rm -rf $archivedir/*

cd $remote_pgdata
cp postgresql.conf postgresql.conf.bak
sed -e 's/#*hot_standby = off/hot_standby = on/' postgresql.conf.bak &#62; postgresql.conf
rm -f postgresql.conf.bak
cat &#62; recovery.conf &lt;&lt; EOT
standby_mode = 'on'
primary_conninfo = 'host="$hostname" port=$port user=repl'
restore_command = 'scp $hostname:$archivedir/%f %p'
EOT
"
            </PRE
></LI
><LI
><P
>/var/lib/pgsql/9.6/data/pgpool_remote_start
          </P
><PRE
CLASS="PROGRAMLISTING"
>#! /bin/sh -x

pghome=/usr/pgsql-9.6
remote_host=$1
remote_pgdata=$2

# Start recovery target PostgreSQL server
ssh -T $remote_host $pghome/bin/pg_ctl -w -D $remote_pgdata start &#62; /dev/null 2&#62;&#38;1 &#60; /dev/null &#38;
          </PRE
></LI
></UL
><P
>        In order to use the online recovery functionality, the functions of <CODE
CLASS="FUNCTION"
>pgpool_recovery</CODE
>, <CODE
CLASS="FUNCTION"
>pgpool_remote_start</CODE
>, <CODE
CLASS="FUNCTION"
>pgpool_switch_xlog</CODE
> are required, so we need install <CODE
CLASS="FUNCTION"
>pgpool_recovery</CODE
> on template1 of <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> server <TT
CLASS="LITERAL"
>osspc19</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
># su - postgres
$ psql template1
=# CREATE EXTENSION pgpool_recovery;
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-AUTH"
>7.3.5.4. Client Authentication Configuration</A
></H3
><P
>Because in the section <A
HREF="example-cluster.html#EXAMPLE-CLUSTER-PRE-SETUP"
>Before Starting</A
>, we already set <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> authentication method to <ACRONYM
CLASS="ACRONYM"
>md5</ACRONYM
>, it is necessary to set a client authentication by <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> to connect to backend nodes. When installing from RPM, the <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> configuration file <TT
CLASS="FILENAME"
>pool_hba.conf</TT
> is in <TT
CLASS="FILENAME"
>/etc/pgpool-II</TT
>. By default, pool_hba authentication is disabled, and set <TT
CLASS="VARNAME"
>enable_pool_hba = on</TT
> to enable it.
        </P
><PRE
CLASS="PROGRAMLISTING"
>enable_pool_hba = on
        </PRE
><P
>The format of <TT
CLASS="FILENAME"
>pool_hba.conf</TT
> file follows very closely PostgreSQL's <TT
CLASS="FILENAME"
>pg_hba.conf</TT
> format. Set <TT
CLASS="LITERAL"
>pgpool</TT
> and <TT
CLASS="LITERAL"
>postgres</TT
> user's authentication method to <TT
CLASS="LITERAL"
>md5</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
>host    all         pgpool           0.0.0.0/0          md5
host    all         postgres         0.0.0.0/0          md5
        </PRE
><P
>To use md5 authentication, we need to register the user name and password in file <TT
CLASS="FILENAME"
>pool_passwd</TT
>. Execute command <TT
CLASS="COMMAND"
>pg_md5 --md5auth --username=&lt;user name&gt; &lt;password&gt;</TT
> to regist user name and MD5-hashed password in file <TT
CLASS="FILENAME"
>pool_passwd</TT
>. If <TT
CLASS="FILENAME"
>pool_passwd</TT
> doesn't exist yet, it will be created in the same directory as <TT
CLASS="FILENAME"
>pgpool.conf</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
># pg_md5 --md5auth --username=pgpool &lt;password of pgpool user&gt;
# pg_md5 --md5auth --username=postgres &lt;password of postgres user&gt;
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-WATCHDOG"
>7.3.5.5. Watchdog Configuration</A
></H3
><P
>        Enable watchdog functionality on <TT
CLASS="LITERAL"
>osspc16</TT
>, <TT
CLASS="LITERAL"
>osspc17</TT
>, <TT
CLASS="LITERAL"
>osspc18</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
>use_watchdog = on
        </PRE
><P
>        Specify virtual IP address that accepts connections from clients on <TT
CLASS="LITERAL"
>osspc16</TT
>, <TT
CLASS="LITERAL"
>osspc17</TT
>, <TT
CLASS="LITERAL"
>osspc18</TT
>. Ensure that the IP address set to virtual IP isn't used yet.
        </P
><PRE
CLASS="PROGRAMLISTING"
>delegate_IP = '133.137.174.153'
        </PRE
><P
>        Specify the hostname and port number of each <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> server.
        </P
><P
></P
><UL
><LI
><P
>              <TT
CLASS="LITERAL"
>osspc16</TT
>
            </P
><PRE
CLASS="PROGRAMLISTING"
>wd_hostname = 'osspc16'
wd_port = 9000
            </PRE
></LI
><LI
><P
>              <TT
CLASS="LITERAL"
>osspc17</TT
>
            </P
><PRE
CLASS="PROGRAMLISTING"
>wd_hostname = 'osspc17'
wd_port = 9000
            </PRE
></LI
><LI
><P
>              <TT
CLASS="LITERAL"
>osspc18</TT
>
            </P
><PRE
CLASS="PROGRAMLISTING"
>wd_hostname = 'osspc18'
wd_port = 9000
            </PRE
></LI
></UL
><P
>          Specify the hostname, <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> port number, and watchdog port number of monitored <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> servers on each <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> server.
        </P
><P
></P
><UL
><LI
><P
>              <TT
CLASS="LITERAL"
>osspc16</TT
>
            </P
><PRE
CLASS="PROGRAMLISTING"
># - Other pgpool Connection Settings -

other_pgpool_hostname0 = 'osspc17'
                                    # Host name or IP address to connect to for other pgpool 0
                                    # (change requires restart)
other_pgpool_port0 = 9999
                                    # Port number for other pgpool 0
                                    # (change requires restart)
other_wd_port0 = 9000
                                    # Port number for other watchdog 0
                                    # (change requires restart)
other_pgpool_hostname1 = 'osspc18'
other_pgpool_port1 = 9999
other_wd_port1 = 9000
            </PRE
></LI
><LI
><P
>              <TT
CLASS="LITERAL"
>osspc17</TT
>
            </P
><PRE
CLASS="PROGRAMLISTING"
># - Other pgpool Connection Settings -

other_pgpool_hostname0 = 'osspc16'
                                    # Host name or IP address to connect to for other pgpool 0
                                    # (change requires restart)
other_pgpool_port0 = 9999
                                    # Port number for other pgpool 0
                                    # (change requires restart)
other_wd_port0 = 9000
                                    # Port number for other watchdog 0
                                    # (change requires restart)
other_pgpool_hostname1 = 'osspc18'
other_pgpool_port1 = 9999
other_wd_port1 = 9000
            </PRE
></LI
><LI
><P
>              <TT
CLASS="LITERAL"
>osspc18</TT
>
            </P
><PRE
CLASS="PROGRAMLISTING"
># - Other pgpool Connection Settings -

other_pgpool_hostname0 = 'osspc16'
                                    # Host name or IP address to connect to for other pgpool 0
                                    # (change requires restart)
other_pgpool_port0 = 9999
                                    # Port number for other pgpool 0
                                    # (change requires restart)
other_wd_port0 = 9000
                                    # Port number for other watchdog 0
                                    # (change requires restart)
other_pgpool_hostname1 = 'osspc17'
other_pgpool_port1 = 9999
other_wd_port1 = 9000
            </PRE
></LI
></UL
><P
>          Specify the hostname and port number of destination for sending heartbeat signal on <TT
CLASS="LITERAL"
>osspc16</TT
>, <TT
CLASS="LITERAL"
>osspc17</TT
>, <TT
CLASS="LITERAL"
>osspc18</TT
>.
        </P
><P
></P
><UL
><LI
><P
>              <TT
CLASS="LITERAL"
>osspc16</TT
>
            </P
><PRE
CLASS="PROGRAMLISTING"
>heartbeat_destination0 = 'osspc17'
                                    # Host name or IP address of destination 0
                                    # for sending heartbeat signal.
                                    # (change requires restart)
heartbeat_destination_port0 = 9694
                                    # Port number of destination 0 for sending
                                    # heartbeat signal. Usually this is the
                                    # same as wd_heartbeat_port.
                                    # (change requires restart)
heartbeat_device0 = ''
                                    # Name of NIC device (such like 'eth0')
                                    # used for sending/receiving heartbeat
                                    # signal to/from destination 0.
                                    # This works only when this is not empty
                                    # and pgpool has root privilege.
                                    # (change requires restart)

heartbeat_destination1 = 'osspc18'
heartbeat_destination_port1 = 9694
heartbeat_device1 = ''

            </PRE
></LI
><LI
><P
>              <TT
CLASS="LITERAL"
>osspc17</TT
>
            </P
><PRE
CLASS="PROGRAMLISTING"
>heartbeat_destination0 = 'osspc16'
                                    # Host name or IP address of destination 0
                                    # for sending heartbeat signal.
                                    # (change requires restart)
heartbeat_destination_port0 = 9694
                                    # Port number of destination 0 for sending
                                    # heartbeat signal. Usually this is the
                                    # same as wd_heartbeat_port.
                                    # (change requires restart)
heartbeat_device0 = ''
                                    # Name of NIC device (such like 'eth0')
                                    # used for sending/receiving heartbeat
                                    # signal to/from destination 0.
                                    # This works only when this is not empty
                                    # and pgpool has root privilege.
                                    # (change requires restart)

heartbeat_destination1 = 'osspc18'
heartbeat_destination_port1 = 9694
heartbeat_device1 = ''

            </PRE
></LI
><LI
><P
>              <TT
CLASS="LITERAL"
>osspc18</TT
>
            </P
><PRE
CLASS="PROGRAMLISTING"
>heartbeat_destination0 = 'osspc16'
                                    # Host name or IP address of destination 0
                                    # for sending heartbeat signal.
                                    # (change requires restart)
heartbeat_destination_port0 = 9694
                                    # Port number of destination 0 for sending
                                    # heartbeat signal. Usually this is the
                                    # same as wd_heartbeat_port.
                                    # (change requires restart)
heartbeat_device0 = ''
                                    # Name of NIC device (such like 'eth0')
                                    # used for sending/receiving heartbeat
                                    # signal to/from destination 0.
                                    # This works only when this is not empty
                                    # and pgpool has root privilege.
                                    # (change requires restart)

heartbeat_destination1 = 'osspc17'
heartbeat_destination_port1 = 9694
heartbeat_device1 = ''
            </PRE
></LI
></UL
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-PGPOOL-CONFIG-PCP"
>7.3.5.6. PCP Command Configuration</A
></H3
><P
>          Because user authentication is required to use the <TT
CLASS="LITERAL"
>PCP</TT
> command, we specify user name and <TT
CLASS="LITERAL"
>md5</TT
> encrypted password in <TT
CLASS="FILENAME"
>pcp.conf</TT
>. Here we create the encrypted password for user <TT
CLASS="LITERAL"
>postgres</TT
>, and add &lt;username: encrypted password&gl; in <TT
CLASS="FILENAME"
>/etc/pgpool-II/pcp.conf</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
># pg_md5 -p
Password: (input password)
(paste the md5 encrypted password to pcp.conf)

# vi /etc/pgpool-II/pcp.conf
(add password entry)
user name:md5 encrypted password
        </PRE
><P
>The settings of Pgpool-II is completed.
        </P
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-START-STOP"
>7.3.6. Starting/Stopping Pgpool-II</A
></H2
><P
>        Next we start <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>. Before starting <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>, please start <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> servers first. Also, when stopping <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
>, it is necessary to stop Pgpool-II first.
      </P
><P
></P
><UL
><LI
><P
>Starting <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
          </P
><P
>            In section <A
HREF="example-cluster.html#EXAMPLE-CLUSTER-PRE-SETUP"
>Before Starting</A
>, we already set the auto-start of <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>. To start <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>, restart the whole system or execute the following command.
          </P
><PRE
CLASS="PROGRAMLISTING"
># systemctl start pgpool.service
          </PRE
></LI
><LI
><P
>            Stopping <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>
          </P
><PRE
CLASS="PROGRAMLISTING"
># systemctl stop pgpool.service
          </PRE
></LI
></UL
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-LOG"
>7.3.7. Log</A
></H2
><P
>        Use <TT
CLASS="COMMAND"
>journalctl</TT
> command to see <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> logs.
      </P
><PRE
CLASS="PROGRAMLISTING"
># journalctl -a | grep pgpool
      </PRE
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXAMPLE-CLUSTER-TRY"
>7.3.8. How to use</A
></H2
><P
>        Let's start to use <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
>. First, let's start <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> on <TT
CLASS="LITERAL"
>osspc16</TT
>, <TT
CLASS="LITERAL"
>osspc17</TT
>, <TT
CLASS="LITERAL"
>osspc18</TT
> by using the following command.
      </P
><PRE
CLASS="PROGRAMLISTING"
># systemctl start pgpool.service
      </PRE
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-TRY-STANDBY"
>7.3.8.1. Set up PostgreSQL standby server</A
></H3
><P
>First, we should set up <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> standby server by using Pgpool-II online recovery functionality. Ensure that <TT
CLASS="FILENAME"
>recovery_1st_stage</TT
> and <TT
CLASS="FILENAME"
>pgpool_remote_start</TT
> scripts used by <TT
CLASS="COMMAND"
>pcp_recovery_node</TT
> command are in database cluster directory of <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> primary server (<TT
CLASS="LITERAL"
>osspc19</TT
>).
        </P
><PRE
CLASS="PROGRAMLISTING"
># pcp_recovery_node -h 133.137.174.153 -p 9898 -U postgres -n 1
      </PRE
><P
>        After executing <TT
CLASS="COMMAND"
>pcp_recovery_node</TT
> command, vertify that <TT
CLASS="LITERAL"
>osspc20</TT
> is started as a <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> standby server.
      </P
><PRE
CLASS="PROGRAMLISTING"
># psql -h 133.137.174.153 -p 9999 -U pgpool postgres

postgres=&#62; show pool_nodes;
 node_id | hostname | port | status | lb_weight |  role   | select_cnt | load_balance_node | replication_delay
---------+----------+------+--------+-----------+---------+------------+-------------------+-------------------
 0       | osspc19  | 5432 | up     | 0.500000  | primary | 0          | true              | 0
 1       | osspc20  | 5432 | up     | 0.500000  | standby | 0          | false             | 0
      </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-TRY-WATCHDOG"
>7.3.8.2. Switching active/standby watchdog</A
></H3
><P
>          Confirm the watchdog status by using <TT
CLASS="COMMAND"
>pcp_watchdog_info</TT
>. The <TT
CLASS="COMMAND"
>Pgpool-II</TT
> server which is started first run as <TT
CLASS="LITERAL"
>MASTER</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
># pcp_watchdog_info -h 133.137.174.153 -p 9898 -U postgres
Password:
3 YES osspc16:9999 Linux osspc16 osspc16

osspc16:9999 Linux osspc16 osspc16 9999 9000 4 MASTER  #The Pgpool-II server started first becames "MASTER".
osspc17:9999 Linux osspc17 osspc17 9999 9000 7 STANDBY #run as standby
osspc18:9999 Linux osspc18 osspc18 9999 9000 7 STANDBY #run as standby
        </PRE
><P
>Stop active server <TT
CLASS="LITERAL"
>osspc16</TT
>, then <TT
CLASS="LITERAL"
>osspc17</TT
> or <TT
CLASS="LITERAL"
>osspc18</TT
> will be promoted to active server. To stop <TT
CLASS="LITERAL"
>osspc16</TT
>, we can stop <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> service or shutdown the whole system. Here, we stop <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> service.
        </P
><PRE
CLASS="PROGRAMLISTING"
>[root@osspc16 ~]# systemctl stop pgpool.service
[root@osspc16 ~]# pcp_watchdog_info -h 133.137.174.153 -p 9898 -U postgres
Password:
3 YES osspc17:9999 Linux osspc17 osspc17

osspc17:9999 Linux osspc17 osspc17 9999 9000 4 MASTER     #osspc17 is promoted to MASTER
osspc16:9999 Linux osspc16 osspc16 9999 9000 10 SHUTDOWN  #osspc16 is stopped
osspc18:9999 Linux osspc18 osspc18 9999 9000 7 STANDBY    #osspc18 runs as STANDBY
        </PRE
><P
>Start <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> (<TT
CLASS="LITERAL"
>osspc16</TT
>) which we have stopped again, and vertify that <TT
CLASS="LITERAL"
>osspc16</TT
> runs as a standby.
        </P
><PRE
CLASS="PROGRAMLISTING"
>[root@osspc16 ~]# systemctl start pgpool.service
[root@osspc16 ~]# pcp_watchdog_info -h 133.137.174.153 -p 9898 -U postgres
Password:
3 YES osspc17:9999 Linux osspc17 osspc17

osspc17:9999 Linux osspc17 osspc17 9999 9000 4 MASTER
osspc16:9999 Linux osspc16 osspc16 9999 9000 7 STANDBY
osspc18:9999 Linux osspc18 osspc18 9999 9000 7 STANDBY
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-TRY-FAILOVER"
>7.3.8.3. Failover</A
></H3
><P
>First, use <TT
CLASS="COMMAND"
>psql</TT
> to connect to <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> via virtual IP, and verify the backend informations.
        </P
><PRE
CLASS="PROGRAMLISTING"
># psql -h 133.137.174.153 -p 9999 -U pgpool postgres

postgres=&#62; show pool_nodes;
 node_id | hostname | port | status | lb_weight |  role   | select_cnt | load_balance_node | replication_delay
---------+----------+------+--------+-----------+---------+------------+-------------------+-------------------
 0       | osspc19  | 5432 | up     | 0.500000  | primary | 0          | true              | 0
 1       | osspc20  | 5432 | up     | 0.500000  | standby | 0          | false             | 0
        </PRE
><P
>Next, stop primary <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> server <TT
CLASS="LITERAL"
>osspc19</TT
>, and verify automatic failover.
        </P
><PRE
CLASS="PROGRAMLISTING"
>$ pg_ctl -D /var/lib/pgsql/9.6/data -m immediate stop
        </PRE
><P
>After stopping <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> on <TT
CLASS="LITERAL"
>osspc19</TT
>, failover occurs and <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> on <TT
CLASS="LITERAL"
>osspc20</TT
> becomes new primary DB.
        </P
><PRE
CLASS="PROGRAMLISTING"
># psql -h 133.137.174.153 -p 9999 -U pgpool postgres

postgres=&#62; show pool_nodes;
 node_id | hostname | port | status | lb_weight |  role   | select_cnt | load_balance_node | replication_delay
---------+----------+------+--------+-----------+---------+------------+-------------------+-------------------
 0       | osspc19  | 5432 | down   | 0.500000  | standby | 0          | false             | 0
 1       | osspc20  | 5432 | up     | 0.500000  | primary | 0          | true              | 0
        </PRE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXAMPLE-CLUSTER-TRY-ONLINE-RECOVERY"
>7.3.8.4. Online Recovery</A
></H3
><P
>Here, we use <SPAN
CLASS="PRODUCTNAME"
>Pgpool-II</SPAN
> online recovery functionality to restore <TT
CLASS="LITERAL"
>osspc19</TT
> (old primary server) as a standby. Before restoring the old primary server, please ensure that <TT
CLASS="FILENAME"
>recovery_1st_stage</TT
> and <TT
CLASS="FILENAME"
>pgpool_remote_start</TT
> scripts exist in database cluster directory of current primary server <TT
CLASS="LITERAL"
>osspc20</TT
>.
        </P
><PRE
CLASS="PROGRAMLISTING"
># pcp_recovery_node -h 133.137.174.153 -p 9898 -U postgres -n 0
        </PRE
><P
>Then verify that <TT
CLASS="LITERAL"
>osspc19</TT
> is started as a standby.
        </P
><PRE
CLASS="PROGRAMLISTING"
># psql -h 133.137.174.153 -p 9999 -U pgpool postgres

postgres=&#62; show pool_nodes;
 node_id | hostname | port | status | lb_weight |  role   | select_cnt | load_balance_node | replication_delay
---------+----------+------+--------+-----------+---------+------------+-------------------+-------------------
 0       | osspc19  | 5432 | up     | 0.500000  | standby | 0          | false             | 0
 1       | osspc20  | 5432 | up     | 0.500000  | primary | 0          | true              | 0
        </PRE
></DIV
></DIV
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="example-watchdog.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.html"
ACCESSKEY="H"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="example-aws.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Watchdog Configuration Example</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="example-configs.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>AWS Configuration Example</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>