<!-- MHonArc v2.1.0 -->
<!--X-Subject: [pgsql&#45;jp 7711] vacuum -->
<!--X-From: Tatsuo Ishii <t&#45;ishii@sra.co.jp> -->
<!--X-Date: Wed, 24 Mar 1999 21:20:12 +0900 -->
<!--X-Message-Id: 199903241220.VAA01088@ext16.sra.co.jp -->
<!--X-ContentType: text/plain -->
<!--X-Reference-Id: 36F8B189F0.AB26SAKAIDA@mail.psn.ne.jp -->
<!--X-Head-End-->
<HTML>
<HEAD>
<TITLE>[pgsql-jp 7711] vacuum </TITLE>
<LINK REV="made" HREF="mailto:t-ishii@sra.co.jp">
</HEAD>
<BODY BGCOLOR="#ffffff">
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<HR>
[<A HREF="msg00454.html">Date Prev</A>][<A HREF="msg00456.html">Date Next</A>][<A HREF="msg00450.html">Thread Prev</A>][<A HREF="msg00475.html">Thread Next</A>][<A HREF="index.html#00455">Date Index</A>][<A HREF="threads.html#00455">Thread Index</A>]
<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<H1>[pgsql-jp 7711] vacuum</H1>
<HR>
<!--X-Subject-Header-End-->
<UL>
<LI><em>From</em>: Tatsuo Ishii &lt;<A HREF="mailto:t-ishii@sra.co.jp">t-ishii@sra.co.jp</A>&gt;</LI>
<LI><em>Date</em>: Wed, 24 Mar 1999 21:20:12 +0900</LI>
</UL>
<!--X-Head-Body-Sep-Begin-->
<HR>
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<PRE>
石井です。サブジェクト変えました。

&gt; 境田です。

&gt; 　ということは、select count(*) from table_name; は常に全件
&gt; の読みこみを行って調べるのですね。

そういうことです。

&gt; &gt; PostgreSQLでは、vacuum処理のついでにしか統計情報を更新
&gt; &gt; できないのがちょっとつらいんですよね。 本来別の機能なので、
&gt; &gt; ANALYZEコマンドみたいなのがあったらよいと思うのですが
&gt; &gt; （といって私には期待しないでください、どうも言い出しっぺに
&gt; &gt; 回ってくるパターンが多いからなあ）。 これなら他の更新トラン
&gt; &gt; ザクションとの並行処理も問題ないですし。
&gt; &gt;
&gt; 
&gt; 　賛成です。（大いに期待したいです(^^;;)

vacuum analyze only とか:-)

&gt; # 10万件のテストがしたかったのですが、6万数千ぐらいでInsert
&gt;   文が out of memory のエラーになったのです。１万単位で 
&gt;   commitしていますし、postmaster -B 300など行ってみたのです
&gt; 　がダメでした。他にオプションが必要でしょうか？　(ecpgで
&gt; 　テストしています）

1万ごとに commit しているにも関わらず、6万ちょっとでメモリ不足になった
のですか？これはメモリリークという奴に違いないです。つまりバグですね。
# この場合のメモリはたぶん共有メモリ以外なので、-B は関係ないと思います。

ちなみに、私がJDBC使ってデータを生成したときは、begin を使った明示的な
トランザクションの開始を宣言していなかったので、1回の insert ごとに 
commit していたことになりますが、時間はかかったものの、10万件の insert 
は特に問題なく終了しました。うーん、何が違うんだろう。

&gt;   100万件オーダーになると、vacuum処理時間はどのくらいなんで
&gt; しょう。

推測ですが、不要領域の圧縮を含まない vacuum の処理は、データ件数に比例
する程度の時間で処理できると思います。この推測が正しければ、6万件で3秒
なら、100万件でも1分かからないことになりますね。

# ただ、実際には同じ件数でも、タプルサイズによって随分かかる時間が違うよ
# うな気がします。

&gt;vacuum済みの100万件のDBに1000件の追加書込みをして、
&gt; vacuumすると、当然、前回と同じ程度のvacuum時間は必要ですね？

そうですね。

&gt; 　それと、vacuumしなければ、1000件の追加書込みに対する検索は、
&gt; 100万+1000件のsequential scanを行いますか？

ちょっと質問の意味が良く分からないので外しているかも知れませんが、
sequetial scan の場合は vacuum の有無に関わらず、すべてのデータブロッ
クを読み込みます。
---
Tatsuo Ishii
</PRE>

<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
<HR>
<UL><LI><STRONG>Follow-Ups</STRONG>:
<UL>
<LI><STRONG><A NAME="00475" HREF="msg00475.html">[pgsql-jp 7731] Re: vacuum</A></STRONG>
<UL><LI><EM>From:</EM> SAKAIDA &lt;sakaida@psn.ne.jp&gt;</LI></UL></LI>
</UL></LI></UL>
<!--X-Follow-Ups-End-->
<!--X-References-->
<UL><LI><STRONG>References</STRONG>:
<UL>
<LI><STRONG><A NAME="00450" HREF="msg00450.html">[pgsql-jp 7706] Re: Linux WORLD の記事</A></STRONG>
<UL><LI><EM>From:</EM> SAKAIDA &lt;sakaida@psn.ne.jp&gt;</LI></UL></LI>
</UL></LI></UL>
<!--X-References-End-->
<!--X-BotPNI-->
<UL>
<LI>Prev by Date:
<STRONG><A HREF="msg00454.html">[pgsql-jp 7710] Re: about compile</A></STRONG>
</LI>
<LI>Next by Date:
<STRONG><A HREF="msg00456.html">[pgsql-jp 7712] Re: KANJI code conversion</A></STRONG>
</LI>
<LI>Prev by thread:
<STRONG><A HREF="msg00450.html">[pgsql-jp 7706] Re: Linux WORLD の記事</A></STRONG>
</LI>
<LI>Next by thread:
<STRONG><A HREF="msg00475.html">[pgsql-jp 7731] Re: vacuum</A></STRONG>
</LI>
<LI>Index(es):
<UL>
<LI><A HREF="index.html#00455"><STRONG>Date</STRONG></A></LI>
<LI><A HREF="threads.html#00455"><STRONG>Thread</STRONG></A></LI>
</UL>
</LI>
</UL>

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
</BODY>
</HTML>
